{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First extract features from Customer History. The source of these data will be (1) AS400 MTC1 (2) Roadnet.\n",
      "The features will include:\n",
      "    -Customer type\n",
      "    -On premise\n",
      "    -Days allotted\n",
      "    -Hours allotted per day (Roadnet)\n",
      "    -Average bottles per delivery (cases too)\n",
      "    -Average frequency between orders\n",
      "    -Total number of orders\n",
      "    -Average cases per week\n",
      "    -Distance from depot\n",
      "    -Number of unique SKUs\n",
      "    -Time for Driver to service account\n",
      "    -%Beer, %Wine, %Spirits\n",
      "    -Number of salespeople who sold to\n",
      "    -Profit; Profit/#sales\n",
      "    -Growing customers; Shrinking customers; Steady customers\n",
      "    -Length of time since customer setup\n",
      "    \n",
      "Break it up into parts\n",
      "\n",
      "Reading in file C:\\Users\\pmwash\\Desktop\\Re-Engineered Reports\\Customer Segmentation\\Data\\pw_custseg 01-2016.csv\n",
      "Reading in file C:\\Users\\pmwash\\Desktop\\Re-Engineered Reports\\Customer Segmentation\\Data\\pw_custseg 02-2016.csv\n",
      "Reading in file C:\\Users\\pmwash\\Desktop\\Re-Engineered Reports\\Customer Segmentation\\Data\\pw_custseg 03-2016.csv\n",
      "Reading in file C:\\Users\\pmwash\\Desktop\\Re-Engineered Reports\\Customer Segmentation\\Data\\pw_custseg 04-2016.csv\n",
      "Reading in file C:\\Users\\pmwash\\Desktop\\Re-Engineered Reports\\Customer Segmentation\\Data\\pw_custseg 05-2016.csv\n",
      "Reading in file C:\\Users\\pmwash\\Desktop\\Re-Engineered Reports\\Customer Segmentation\\Data\\pw_custseg 06-2016.csv\n",
      "Reading in file C:\\Users\\pmwash\\Desktop\\Re-Engineered Reports\\Customer Segmentation\\Data\\pw_custseg 07-2016.csv\n",
      "Reading in file C:\\Users\\pmwash\\Desktop\\Re-Engineered Reports\\Customer Segmentation\\Data\\pw_custseg 08-2016.csv\n",
      "Reading in file C:\\Users\\pmwash\\Desktop\\Re-Engineered Reports\\Customer Segmentation\\Data\\pw_custseg 09-2016.csv\n",
      "Reading in file C:\\Users\\pmwash\\Desktop\\Re-Engineered Reports\\Customer Segmentation\\Data\\pw_custseg 10-2016.csv\n",
      "Reading in file C:\\Users\\pmwash\\Desktop\\Re-Engineered Reports\\Customer Segmentation\\Data\\pw_custseg 11-2016.csv\n",
      "Reading in file C:\\Users\\pmwash\\Desktop\\Re-Engineered Reports\\Customer Segmentation\\Data\\pw_custseg 12-2016.csv\n",
      "\n",
      "\n",
      "Aggregating by Customer\n",
      "\n",
      "\n",
      "                     TermsCode  OffDayDeliveries  \\\n",
      "Warehouse CustomerId                               \n",
      "Columbia  3000019           50                 9   \n",
      "          3000020           50                 1   \n",
      "          3000021           50                 2   \n",
      "          3000022           50                 8   \n",
      "          3000023           12               265   \n",
      "\n",
      "                      CasesSoldOnLastSellingDayOfMonth    Bottles  ProductId  \\\n",
      "Warehouse CustomerId                                                           \n",
      "Columbia  3000019                           168.000000   137952.0          7   \n",
      "          3000020                             0.000000    60768.0          7   \n",
      "          3000021                            72.000000   100368.0          7   \n",
      "          3000022                           600.000000   325440.0          7   \n",
      "          3000023                          1167.833333  1359542.0        508   \n",
      "\n",
      "                      InvoiceLine         Cases  SupplierId  \\\n",
      "Warehouse CustomerId                                          \n",
      "Columbia  3000019              56   5952.000000           3   \n",
      "          3000020              31   2616.000000           3   \n",
      "          3000021              52   4380.000000           3   \n",
      "          3000022              77  13800.000000           3   \n",
      "          3000023            1652  27858.041667          57   \n",
      "\n",
      "                      CasesSoldOnHolidayWeeks       Cost  \\\n",
      "Warehouse CustomerId                                       \n",
      "Columbia  3000019                       540.0    6520.16   \n",
      "          3000020                       228.0    2764.20   \n",
      "          3000021                       324.0    4927.04   \n",
      "          3000022                       972.0   13837.21   \n",
      "          3000023                      1508.5  102702.85   \n",
      "\n",
      "                      AllottedWeeklyDeliveryDays  BrandId  SalespersonId  \\\n",
      "Warehouse CustomerId                                                       \n",
      "Columbia  3000019                            1.0        7              1   \n",
      "          3000020                            1.0        7              1   \n",
      "          3000021                            1.0        7              1   \n",
      "          3000022                            1.0        7              1   \n",
      "          3000023                            1.0      383              1   \n",
      "\n",
      "                      Invoice    Revenue  CreditLimit  CasesPerDay  \\\n",
      "Warehouse CustomerId                                                 \n",
      "Columbia  3000019          40    8853.17        500.0    28.478469   \n",
      "          3000020          20    3761.19        500.0    12.516746   \n",
      "          3000021          33    6694.52        500.0    20.956938   \n",
      "          3000022          51   18837.58        500.0    66.028708   \n",
      "          3000023         185  130104.64        500.0   133.292065   \n",
      "\n",
      "                      BottlesPerDay  InvoicesPerDay  InvoiceLinesPerDay  \\\n",
      "Warehouse CustomerId                                                      \n",
      "Columbia  3000019        660.057416        0.191388            0.267943   \n",
      "          3000020        290.755981        0.095694            0.148325   \n",
      "          3000021        480.229665        0.157895            0.248804   \n",
      "          3000022       1557.129187        0.244019            0.368421   \n",
      "          3000023       6504.985646        0.885167            7.904306   \n",
      "\n",
      "                      RevenuePerDay  AvgDaysBetweenInvoices  \\\n",
      "Warehouse CustomerId                                          \n",
      "Columbia  3000019         42.359665                5.225000   \n",
      "          3000020         17.996124               10.450000   \n",
      "          3000021         32.031196                6.333333   \n",
      "          3000022         90.131962                4.098039   \n",
      "          3000023        622.510239                1.129730   \n",
      "\n",
      "                      CasesSoldOnLastSellingDayOfMonth_PercentOfTotal  \\\n",
      "Warehouse CustomerId                                                    \n",
      "Columbia  3000019                                            0.028226   \n",
      "          3000020                                            0.000000   \n",
      "          3000021                                            0.016438   \n",
      "          3000022                                            0.043478   \n",
      "          3000023                                            0.041921   \n",
      "\n",
      "                      CasesSoldOnHolidayWeeks_PercentOfTotal  \\\n",
      "Warehouse CustomerId                                           \n",
      "Columbia  3000019                                   0.090726   \n",
      "          3000020                                   0.087156   \n",
      "          3000021                                   0.073973   \n",
      "          3000022                                   0.070435   \n",
      "          3000023                                   0.054150   \n",
      "\n",
      "                      CasesPerUniqueBrand  CasesPerUniqueSalesperson  \\\n",
      "Warehouse CustomerId                                                   \n",
      "Columbia  3000019              850.285714                5952.000000   \n",
      "          3000020              373.714286                2616.000000   \n",
      "          3000021              625.714286                4380.000000   \n",
      "          3000022             1971.428571               13800.000000   \n",
      "          3000023               72.736401               27858.041667   \n",
      "\n",
      "                      CasesPerInvoice  CasesPerInvoiceLine        GP  \\\n",
      "Warehouse CustomerId                                                   \n",
      "Columbia  3000019          148.800000           106.285714  1.357815   \n",
      "          3000020          130.800000            84.387097  1.360679   \n",
      "          3000021          132.727273            84.230769  1.358731   \n",
      "          3000022          270.588235           179.220779  1.361371   \n",
      "          3000023          150.584009            16.863221  1.266807   \n",
      "\n",
      "                      GPperBrand  GPperSalesperson  BrandsPerSalesperson  \\\n",
      "Warehouse CustomerId                                                       \n",
      "Columbia  3000019       0.193974          1.357815                   7.0   \n",
      "          3000020       0.194383          1.360679                   7.0   \n",
      "          3000021       0.194104          1.358731                   7.0   \n",
      "          3000022       0.194482          1.361371                   7.0   \n",
      "          3000023       0.003308          1.266807                 383.0   \n",
      "\n",
      "                     DeliveryDays         CustomerType SeasonCreditLimit  \\\n",
      "Warehouse CustomerId                                                       \n",
      "Columbia  3000019         ____F__  Supermarket/Grocery                 Y   \n",
      "          3000020         __W____  Supermarket/Grocery                 Y   \n",
      "          3000021         __W____  Supermarket/Grocery                 Y   \n",
      "          3000022         ____F__  Supermarket/Grocery                 Y   \n",
      "          3000023         __W____    Convenience Store                 Y   \n",
      "\n",
      "                      OnPremise DisplayCaseClass  \n",
      "Warehouse CustomerId                              \n",
      "Columbia  3000019             0              NaN  \n",
      "          3000020             0              NaN  \n",
      "          3000021             0              NaN  \n",
      "          3000022             0              NaN  \n",
      "          3000023             0              NaN  \n"
     ]
    }
   ],
   "source": [
    "print('''\n",
    "First extract features from Customer History. The source of these data will be (1) AS400 MTC1 (2) Roadnet.\n",
    "The features will include:\n",
    "    -Customer type\n",
    "    -On premise\n",
    "    -Days allotted\n",
    "    -Hours allotted per day (Roadnet)\n",
    "    -Average bottles per delivery (cases too)\n",
    "    -Average frequency between orders\n",
    "    -Total number of orders\n",
    "    -Average cases per week\n",
    "    -Distance from depot\n",
    "    -Number of unique SKUs\n",
    "    -Time for Driver to service account\n",
    "    -%Beer, %Wine, %Spirits\n",
    "    -Number of salespeople who sold to\n",
    "    -Profit; Profit/#sales\n",
    "    -Growing customers; Shrinking customers; Steady customers\n",
    "    -Length of time since customer setup\n",
    "    \n",
    "Break it up into parts\n",
    "''')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from IPython.display import display\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def generate_calendar(year):\n",
    "    from pandas.tseries.offsets import YearEnd\n",
    "    from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "    \n",
    "    start_date = pd.to_datetime('1/1/'+str(year))\n",
    "    end_date = start_date + YearEnd()\n",
    "    DAT = pd.date_range(str(start_date), str(end_date), freq='D')\n",
    "    WK = [d.strftime('%U') for d in DAT]\n",
    "    MO = [d.strftime('%B') for d in DAT]\n",
    "    holidays = USFederalHolidayCalendar().holidays(start=start_date, end=end_date)\n",
    "\n",
    "    DAYZ = pd.DataFrame({'Date':DAT, 'WeekNumber':WK, 'Month':MO})\n",
    "    \n",
    "    DAYZ['Year'] = [format(d, '%Y') for d in DAT]\n",
    "    DAYZ['Weekday'] = [format(d, '%A') for d in DAT]\n",
    "    DAYZ['DOTM'] = [format(d, '%d') for d in DAT]\n",
    "    DAYZ['IsWeekday'] = DAYZ.Weekday.isin(['Monday','Tuesday','Wednesday','Thursday','Friday'])\n",
    "    DAYZ['IsProductionDay'] = DAYZ.Weekday.isin(['Tuesday','Wednesday','Thursday','Friday'])\n",
    "    last_biz_day = [str(format(dat, '%Y-%m-%d')) for dat in pd.date_range(start_date, end_date, freq='BM')]\n",
    "    DAYZ['LastSellingDayOfMonth'] = [dat in last_biz_day for dat in DAYZ['Date'].astype(str)]\n",
    "\n",
    "    DAYZ.loc[DAYZ.WeekNumber.isin(['00','01','02','03','04','05','06','07','08','09','50','51','52','53']), 'Season'] = 'Winter'\n",
    "    DAYZ.loc[DAYZ.WeekNumber.isin(['10','11','12','13','14','15','16','17','18','19','20','21','22']), 'Season'] = 'Spring'\n",
    "    DAYZ.loc[DAYZ.WeekNumber.isin(['23','24','25','26','27','28','29','30','31','32','33','34','35']), 'Season'] = 'Summer'\n",
    "    DAYZ.loc[DAYZ.WeekNumber.isin(['36','37','38','39','40','41','42','43','44','45','46','47','48','49']), 'Season'] = 'Autumn'\n",
    "    DAYZ['Holiday'] = DAYZ.Date.isin(holidays)\n",
    "    DAYZ['HolidayWeek'] = DAYZ['Holiday'].rolling(window=7,center=True,min_periods=1).sum()\n",
    "    DAYZ['ShipWeek'] = ['A' if int(wk) % 2 == 0 else 'B' for wk in WK]\n",
    "\n",
    "    DAYZ.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return DAYZ\n",
    "\n",
    "def generate_newcust_cutoff():\n",
    "    from datetime import datetime as dt\n",
    "    if dt.now().month == 1:\n",
    "        last_month = '12'\n",
    "    else:\n",
    "        last_month = str(dt.now().month - 1).zfill(2)\n",
    "    if dt.now().month == 1:\n",
    "            this_year = str(dt.now().year - 1)\n",
    "    else:\n",
    "        this_year = str(dt.now().year)\n",
    "    m_y_cutoff = last_month + '-' + this_year\n",
    "    return m_y_cutoff\n",
    "\n",
    "\n",
    "def as400_date(dat):\n",
    "    '''Accepts date as formatted in AS400'''\n",
    "    dat = str(dat)\n",
    "    dat = dat[-6:]\n",
    "    dat = pd.to_datetime(dt.strptime(dat, '%y%m%d'))\n",
    "    return dat\n",
    "\n",
    "\n",
    "def get_production_days(year):\n",
    "    T_F = ['Tuesday','Wednesday','Thursday','Friday']\n",
    "    dayz = np.sum([int(str(format(dat, '%A')) in T_F) for dat in pd.date_range('1/1/'+str(year), periods=365, freq='d')])\n",
    "    return dayz\n",
    "\n",
    "def sum_digits_in_string(digit):\n",
    "    return sum(int(x) for x in digit if x.isdigit())\n",
    "\n",
    "def extract_customer_delivery_info(deliveries, year):\n",
    "    '''Extract delivery information about customers'''\n",
    "    import itertools\n",
    "    from pandas import DataFrame, Series\n",
    "    weeklookup = generate_calendar(year=year)\n",
    "    deliveries = deliveries.merge(weeklookup, on='Date')\n",
    "    \n",
    "    week_plan, week_shipped = deliveries.ShipWeekPlan.tolist(), deliveries.ShipWeek.tolist()\n",
    "    \n",
    "    deliveries.Ship = del_days = [str('%07d'% int(str(day).zfill(0))) for day in deliveries.Ship.astype(str).tolist()]\n",
    "\n",
    "    mon = Series([d[-7:][:1] for d in del_days]).map({'1':'M','0':'_'})\n",
    "    tue = Series([d[-6:][:1] for d in del_days]).map({'1':'T','0':'_'})\n",
    "    wed = Series([d[-5:][:1] for d in del_days]).map({'1':'W','0':'_'})\n",
    "    thu = Series([d[-4:][:1] for d in del_days]).map({'1':'R','0':'_'})\n",
    "    fri = Series([d[-3:][:1] for d in del_days]).map({'1':'F','0':'_'})\n",
    "    sat = Series([d[-2:][:1] for d in del_days]).map({'1':'S','0':'_'})\n",
    "    sun = Series([d[-1:][:1] for d in del_days]).map({'1':'U','0':'_'})\n",
    "    \n",
    "    deliveries['DeliveryDays'] = del_days = list(itertools.chain.from_iterable([mon + tue + wed + thu + fri + sat + sun]))\n",
    "    \n",
    "    weekday = deliveries.Weekday = [d[:3] for d in deliveries.Weekday.astype(str).tolist()]\n",
    "    _days = pd.DataFrame(data={'Weekday':weekday, 'WeekPlanned':week_plan, 'WeekShipped':week_shipped, 'DelDays':del_days}) #'Monday':mon, 'Tuesday':tue, 'Wednesday':wed, 'Thursday':thu, 'Friday':fri, 'Saturday':sat, 'Sunday':sun,\n",
    "    day_list = _days['WeekPlanned'].tolist()\n",
    "    _days['WeekPlanned'] = _week_planned = [d if d in ['A','B'] else '' for d in day_list]\n",
    "    \n",
    "    _week_actual = _days.WeekShipped.tolist()\n",
    "    _week_plan = _days['WeekPlanned'] = [ship_week if plan_week == '' else plan_week for ship_week, plan_week in zip(_week_actual, _week_planned)]\n",
    "    _days['OffWeek'] = _off_week = [p != a for p, a in zip(_week_plan, _week_actual)]\n",
    "    \n",
    "    off_mon = [str('M' not in d and w == 'Mon')[:1] for d, w in zip(del_days, weekday)]\n",
    "    off_tue = [str('T' not in d and w == 'Tue')[:1] for d, w in zip(del_days, weekday)]\n",
    "    off_wed = [str('W' not in d and w == 'Wed')[:1] for d, w in zip(del_days, weekday)]\n",
    "    off_thu = [str('R' not in d and w == 'Thu')[:1] for d, w in zip(del_days, weekday)]\n",
    "    off_fri = [str('F' not in d and w == 'Fri')[:1] for d, w in zip(del_days, weekday)]\n",
    "    off_sat = [str('S' not in d and w == 'Sat')[:1] for d, w in zip(del_days, weekday)]\n",
    "    off_sun = [str('U' not in d and w == 'Sun')[:1] for d, w in zip(del_days, weekday)]\n",
    "    \n",
    "    _off_days = DataFrame({'Mon':off_mon, 'Tue':off_tue, 'Wed':off_wed, 'Thu':off_thu, \n",
    "                           'Fri':off_fri, 'Sat':off_sat, 'Sun':off_sun, 'OffWeek':_off_week, 'Weekday':weekday})\n",
    "    _off_days = _off_days[['Mon','Tue','Wed','Thu','Fri','Sat','Sun','Weekday','OffWeek']]    \n",
    "    _off_days['OffDayDelivery'] = (_off_days['Mon'] == 'T') | (_off_days['Tue'] == 'T') | (_off_days['Wed'] == 'T') | (_off_days['Thu'] == 'T') | (_off_days['Fri'] == 'T') | (_off_days['Sat'] == 'T') | (_off_days['Sun'] == 'T') | (_off_days['OffWeek'] == True)                \n",
    "\n",
    "    setup_date = deliveries.CustomerSetup.astype(str).tolist()\n",
    "    setup_month = Series([d.zfill(4)[:2] for d in setup_date])\n",
    "    setup_year = Series([\"20\" + s[-2:] if int(s[-2:]) < 20 else \"19\" + s[-2:] for s in setup_date]) #this_century = [int(d[-2:]) < 20 for d in setup_date]\n",
    "    deliveries['CustomerSetup'] = c_setup = [str(mon) + '-' + str(yr) for mon, yr in zip(setup_month, setup_year)]\n",
    "    \n",
    "    m_y_cutoff = generate_newcust_cutoff()\n",
    "    deliveries['NewCustomer'] = [1 if m_y_cutoff == setup else 0 for setup in c_setup]\n",
    "    deliveries['OffDayDeliveries'] =  _off_days.OffDayDelivery.astype(int)\n",
    "    \n",
    "    _n_days = deliveries.Ship.astype(str).tolist()\n",
    "    deliveries['AllottedWeeklyDeliveryDays'] = [sum_digits_in_string(n) for n in _n_days]\n",
    "    _allot = deliveries['AllottedWeeklyDeliveryDays'].tolist()\n",
    "    _week_ind = deliveries['ShipWeekPlan'].tolist()\n",
    "    deliveries['AllottedWeeklyDeliveryDays'] = [a if w not in ['A','B'] else 0.5 for a, w in zip(_allot, _week_ind)]\n",
    "\n",
    "        ################################# \n",
    "        #### come back later and get addl deliveries\n",
    "        #################################\n",
    "#     _n_days = deliveries.set_index('CustomerId')['AllottedWeeklyDeliveryDays'].to_dict()\n",
    "    \n",
    "#     for_addl_days = ['CustomerId','Week','AllottedWeeklyDeliveryDays','OffDayDeliveries']\n",
    "#     deliveries[for_addl_days].groupby(['CustomerId','Week'])\n",
    "#     deliveries['AdditionalDeliveryDays'] = \n",
    "    \n",
    "#     print('Aggregating by Day.')\n",
    "#     len_unique = lambda x: len(pd.unique(x))\n",
    "#     agg_funcs_day = {'OffDayDeliveries' : {'Count':max}, \n",
    "#                  'Date' : {'Count':len_unique},\n",
    "#                  'Cases' : {'Sum':sum, 'Avg':np.mean},\n",
    "#                  'Dollars' : {'Sum':sum, 'Avg':np.mean},\n",
    "#                  'NewCustomer': lambda x: min(x)}\n",
    "    \n",
    "#     pass_through_cols = ['CustomerId','Customer','Week','Date']\n",
    "#     _agg_byday = DataFrame(deliveries.groupby(pass_through_cols).agg(agg_funcs_day)).reset_index(drop=False)\n",
    "#     _agg_byday = DataFrame(_agg_byday[['CustomerId','Customer','Week','Date','OffDayDeliveries','NewCustomer','Cases','Dollars']])\n",
    "#     _agg_byday.columns = ['%s%s' % (a, '|%s' % b if b else '') for a, b in _agg_byday.columns]\n",
    "#     _agg_byday.columns = ['CustomerId','Customer','Week','Date','Delivery','OffDayDelivery','NewCustomer','Cases|Sum','Cases|Avg','Dollars|Sum','Dollars|Avg']\n",
    "#     _agg_byday['AllottedWeeklyDeliveryDays|Count'] = _agg_byday['CustomerId'].astype(int)\n",
    "#     _agg_byday['AllottedWeeklyDeliveryDays|Count'] = _agg_byday['AllottedWeeklyDeliveryDays|Count'].map(_n_days)\n",
    "    \n",
    "    \n",
    "#     print('Mapping number of deliveries to Customers.')\n",
    "#     # Map number of total deliveries each week by customer\n",
    "#     # to determine whether a customer with TWR deliveries \n",
    "#     # got TWF deliveries -- which is an off-day delivery\n",
    "#     # but not an additional delivery. Use a dictionary {(cust#, week) : n_deliveries_total}\n",
    "#     agg_funcs_week = {'OffDayDelivery' : {'Count':sum},\n",
    "#                       'Delivery' : {'Count':sum},\n",
    "#                       'NewCustomer' : lambda x: min(x)}\n",
    "    \n",
    "#     _agg_byweek = DataFrame(_agg_byday.groupby(['CustomerId','Week']).agg(agg_funcs_week)).reset_index(drop=False)\n",
    "#     _agg_byweek.columns = ['%s%s' % (a, '|%s' % b if b else '') for a, b in _agg_byweek.columns]\n",
    "\n",
    "#     _c = _agg_byweek['CustomerId'].astype(str).tolist()\n",
    "#     _w = _agg_byweek['Week'].astype(str).tolist()\n",
    "#     _agg_byweek['_X'] = [c + ',' + w for c,w in zip(_c,_w)]\n",
    "#     by_week_map = _agg_byweek.set_index('_X')['Delivery|Count'].to_dict()\n",
    "    \n",
    "#     cid = _agg_byday['CustomerId'].astype(str).tolist()\n",
    "#     wkk = _agg_byday['Week'].astype(str).tolist()\n",
    "#     _agg_byday['N_DeliveriesThisWeek'] = [c + ',' + w for c, w in zip(cid, wkk)]\n",
    "#     _agg_byday['N_DeliveriesThisWeek'] = _agg_byday['N_DeliveriesThisWeek'].map(Series(by_week_map))\n",
    "    \n",
    "    \n",
    "#     print('Using custom logic to define Additional Delivery Days.')\n",
    "#     addl_day_criteria_1 = ( _agg_byday.shift(1)['CustomerId'] == _agg_byday['CustomerId'] )\n",
    "#     addl_day_criteria_2 = ( _agg_byday.shift(1)['Week'] == _agg_byday['Week'] )\n",
    "#     addl_day_criteria_3 = ( _agg_byday['OffDayDelivery'] == 1 )\n",
    "#     addl_day_criteria_4 = ( _agg_byday['NewCustomer'] != 1 )\n",
    "#     addl_day_criteria_5 = ( _agg_byday['N_DeliveriesThisWeek'] > _agg_byday['AllottedWeeklyDeliveryDays|Count'] )\n",
    "    \n",
    "#     _agg_byday['AdditionalDeliveryDays'] = Series(addl_day_criteria_1 & addl_day_criteria_2 & addl_day_criteria_3 & addl_day_criteria_4 & addl_day_criteria_5).astype(int)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return deliveries\n",
    "\n",
    "\n",
    "path = 'C:\\\\Users\\\\pmwash\\\\Desktop\\\\Re-Engineered Reports\\\\Customer Segmentation\\\\Data\\\\*.csv'\n",
    "\n",
    "def generate_customer_features(path, year):\n",
    "    '''Reads query for customer segmentation for Roadnet'''\n",
    "    all_files = glob.glob(path)\n",
    "    \n",
    "    DF_OUT = pd.DataFrame()\n",
    "    for file in all_files:\n",
    "        # Specify datatypes from start to avoid issues downstream\n",
    "        print('Reading in file %s' %file)\n",
    "        dtypes = col_names = {'#MCUS#':str,'#MIVDT':str,'#MIVND':str,'#MLIN#':str,'#MPRD#':str,'#MQTYS':np.int64,\n",
    "                    'CSCRDT':str,'CCRLIM':np.float64,'CONPRM':str,'CUSPMC':str,'CDDAY':str,\n",
    "                    '#MEXT$':np.float64,'CTERM@':str,'#MCOS$':np.float64,'CSTOR#':str,'#MCHN#':str,'#MCUSY':str,\n",
    "                    '#MSLSP':str,'#MQPC':np.int64,'#MCLA@':str,'#MSIZ@':str,'#MBRND':str,'#MQTY@':str,\n",
    "                    '#MCMP':str,'#MSUPL':str,'#MCALL':str,'#MPRIO':str,'#MINP#':str,\n",
    "                    '#CSTDTE':str,'CUDSCC':str,'CSHP':str,'CADMBR':str}\n",
    "        c = pd.read_csv(file, header=0, dtype=dtypes)\n",
    "\n",
    "        ## Rename columns to make sense\n",
    "        col_names = {'#MCUS#':'CustomerId','#MIVDT':'Date','#MIVND':'Invoice','#MLIN#':'Line','#MPRD#':'SupplierBrandSizeNumber','#MQTYS':'QuantitySold',\n",
    "                    'CSCRDT':'SeasonCreditLimit','CCRLIM':'CreditLimit','CONPRM':'OnPremise','CUSPMC':'MerchandiseClass','CDDAY':'X2',\n",
    "                    '#MEXT$':'Revenue','CTERM@':'TermsCode','#MCOS$':'Cost','CSTOR#':'BarChainCode','#MCHN#':'ChainId','#MCUSY':'CustomerType',\n",
    "                    '#MSLSP':'SalespersonId','#MQPC':'QPC','#MCLA@':'ClassCode','#MSIZ@':'SizeCode','#MBRND':'BrandId','#MQTY@':'QtyCode',\n",
    "                    '#MCMP':'Warehouse','#MSUPL':'SupplierId','#MCALL':'CallCode','#MPRIO':'Priority','#MINP#':'ProductId','#MPRM@':'X1',\n",
    "                    'CSTDTE':'CustomerSetup','CUDSCC':'DisplayCaseClass','CSHP':'Ship','CADMBR':'ShipWeekPlan'}\n",
    "        c.rename(columns=col_names, inplace=True)\n",
    "        c.drop(labels=['X1','X2'], axis=1, inplace=True)\n",
    "\n",
    "        ## Extract Invoice & Line\n",
    "        c['InvoiceLine'] = [str(a)+'_'+str(b) for a,b in zip(c.Invoice, c.Line)]\n",
    "\n",
    "        ## Extract proper dates and derivative data\n",
    "        c.Date = dat = c.Date.apply(as400_date)\n",
    "        \n",
    "        ## Extract Cases \n",
    "        CS, QPC = c.loc[c['QtyCode'] == 'C', 'QuantitySold'].astype(np.float64), c.loc[c['QtyCode'] == 'B', 'QPC'].astype(np.float64)\n",
    "        BTLS = c.loc[c.QtyCode == 'B', 'QuantitySold'].astype(np.float64)\n",
    "        c.loc[c.QtyCode == 'C', 'Cases'] = CS\n",
    "        c.loc[c.QtyCode == 'B', 'Cases'] = np.divide(BTLS, QPC)\n",
    "\n",
    "        ## Extract Bottles\n",
    "        QPC_tobtl = c.loc[c['QtyCode'] == 'C', 'QPC'].astype(np.float64)\n",
    "        c.loc[c.QtyCode == 'C', 'Bottles'] = np.multiply(CS, QPC_tobtl)\n",
    "        c.loc[c.QtyCode == 'B', 'Bottles'] = BTLS\n",
    "        \n",
    "        ## Get delivery info specified in function above\n",
    "        c = extract_customer_delivery_info(deliveries=c, year=year)\n",
    "        \n",
    "        ## Extract features from data\n",
    "        lastday = pd.DataFrame(c[c.LastSellingDayOfMonth == True][['CustomerId','Cases']].fillna(0).groupby('CustomerId').sum()).reset_index(drop=False)\n",
    "        lastday_dict = dict(zip(lastday.CustomerId, lastday.Cases))\n",
    "        c['CasesSoldOnLastSellingDayOfMonth'] = c.CustomerId.map(lastday_dict)\n",
    "        \n",
    "        holidayweek = pd.DataFrame(c[c.HolidayWeek == True][['CustomerId','Cases']].fillna(0).groupby('CustomerId').sum()).reset_index(drop=False)\n",
    "        holidayweek_dict = dict(zip(holidayweek.CustomerId, holidayweek.Cases))\n",
    "        c['CasesSoldOnHolidayWeeks'] = c.CustomerId.map(holidayweek_dict)\n",
    "        \n",
    "        ## Label customer types, call codes, class codes & warehouse\n",
    "        type_map = {'A':'Bar/Tavern','C':'Country Club','E':'Transportation/Airline','G':'Gambling',\\\n",
    "                        'J':'Hotel/Motel','L':'Restaurant','M':'Military','N':'Fine Dining','O':'Internal',\\\n",
    "                        'P':'Country/Western','S':'Package Store','T':'Supermarket/Grocery','V':'Drug Store',\\\n",
    "                        'Y':'Convenience Store','Z':'Catering','3':'Night Club','5':'Adult Entertainment','6':'Sports Bar',\\\n",
    "                        'I':'Church','F':'Membership Club','B':'Mass Merchandiser','H':'Fraternal Organization',\\\n",
    "                        '7':'Sports Venue'}\n",
    "        c.CustomerType = c.CustomerType.map(type_map)\n",
    "        call_codes = {'01':'Customer Call','02':'ROE/EDI','03':'Salesperson Call','04':'Telesales','BH':'Bill & Hold',\n",
    "                     'BR':'Breakage','CP':'Customer Pickup','FS':'Floor Stock','HJ':'High Jump','KR':'Keg Route',\n",
    "                     'NH':'Non-Highjump','NR':'Non-Roadnet','PL':'Pallets','PR':'Personal','RB':'Redbull',\n",
    "                     'SA':'Sample','SP':'Special','WD':'Withdrawal'}\n",
    "        c.CallCode = c.CallCode.map(call_codes)\n",
    "        product_class_map = {'10':'Liquor', '25':'Spirit Coolers', '50':'Wine', '51':'Fine Wine', '53':'Keg Wine',\n",
    "                                '55':'Sparkling Wine & Champagne', '58':'Package Cider', '59':'Keg Cider', '70':'Wine Coolers',\n",
    "                                '80':'Malt Coolers/3.2 Beer', '84':'High-Alcohol Malt', '85':'Beer', '86':'Keg Beer', \n",
    "                                '87':'Keg Beer w/ Deposit', '88':'High Alcohol Kegs', '90':'Water/Soda', '91':'Other Non-Alcoholic',\n",
    "                                '92':'Red Bull', '95':'Taxable Items - On Premise', '99':'Miscellaneous'}\n",
    "        c.ClassCode = c.ClassCode.map(product_class_map)\n",
    "        whse_map = {'1':'Kansas City','2':'Saint Louis','3':'Columbia','5':'Springfield'}\n",
    "        c.Warehouse = c.Warehouse.map(whse_map)\n",
    "        \n",
    "        ## Append new data to a dataframe that compiles all of it\n",
    "        DF_OUT = DF_OUT.append(c)\n",
    "    \n",
    "    ## Save customer attributes from raw data\n",
    "    attr = ['CustomerId','DeliveryDays','CustomerType','SeasonCreditLimit','OnPremise','DisplayCaseClass']\n",
    "    customer_attributes = DF_OUT[attr].drop_duplicates()\n",
    "    \n",
    "    ## Aggregate together\n",
    "    print('\\n\\nAggregating by Customer\\n\\n')\n",
    "    ## Aggregate data in-memory since files are too large to operate on in raw form\n",
    "    agg_functions = {'Cases' : np.sum, \n",
    "                     'Bottles' : np.sum, \n",
    "                     'Invoice' : pd.Series.nunique, \n",
    "                     'InvoiceLine' : pd.Series.nunique,\n",
    "                     'Revenue' : np.sum, \n",
    "                     'Cost' : np.sum,\n",
    "                     'ProductId' : pd.Series.nunique,\n",
    "                     'BrandId' : pd.Series.nunique,\n",
    "                     'SupplierId' : pd.Series.nunique,\n",
    "                     'SalespersonId' : pd.Series.nunique,\n",
    "                     'TermsCode' : np.max,\n",
    "                     'CreditLimit' : np.max,\n",
    "                     'CasesSoldOnLastSellingDayOfMonth' : np.max,\n",
    "                     'CasesSoldOnHolidayWeeks' : np.max,\n",
    "                     'AllottedWeeklyDeliveryDays' : np.max,\n",
    "                     'OffDayDeliveries' : np.sum\n",
    "                     }\n",
    "    \n",
    "    DF_OUT = pd.DataFrame(DF_OUT.groupby(['Warehouse','CustomerId']).agg(agg_functions)).reset_index(drop=False)\n",
    "    \n",
    "    ## Derive further attributes\n",
    "    T_F = ['Tuesday','Wednesday','Thursday','Friday']\n",
    "    PRODUCTION_DAYZ = np.sum(generate_calendar(year=year)['IsProductionDay']) \n",
    "    per_day_cols = ['Cases','Bottles','Invoice','InvoiceLine','Revenue']\n",
    "    colnames_perday = ['CasesPerDay','BottlesPerDay','InvoicesPerDay','InvoiceLinesPerDay','RevenuePerDay']\n",
    "    DF_OUT[colnames_perday] = np.divide(DF_OUT[per_day_cols], PRODUCTION_DAYZ)\n",
    "    DF_OUT['AvgDaysBetweenInvoices'] = np.divide(1, DF_OUT['InvoicesPerDay'])\n",
    "    DF_OUT['CasesSoldOnLastSellingDayOfMonth_PercentOfTotal'] = np.divide(DF_OUT['CasesSoldOnLastSellingDayOfMonth'], DF_OUT['Cases'])\n",
    "    DF_OUT['CasesSoldOnLastSellingDayOfMonth_PercentOfTotal'] = DF_OUT['CasesSoldOnLastSellingDayOfMonth_PercentOfTotal'].fillna(0)\n",
    "    DF_OUT['CasesSoldOnHolidayWeeks_PercentOfTotal'] = np.divide(DF_OUT['CasesSoldOnHolidayWeeks'], DF_OUT['Cases'])\n",
    "    DF_OUT['CasesSoldOnHolidayWeeks_PercentOfTotal'] = DF_OUT['CasesSoldOnHolidayWeeks_PercentOfTotal'].fillna(0)\n",
    "    DF_OUT['CasesPerUniqueBrand'] = np.divide(DF_OUT['Cases'], DF_OUT['BrandId'])\n",
    "    DF_OUT['CasesPerUniqueSalesperson'] = np.divide(DF_OUT['Cases'], DF_OUT['SalespersonId'])\n",
    "    DF_OUT['CasesPerInvoice'] = np.divide(DF_OUT['Cases'], DF_OUT['Invoice'])\n",
    "    DF_OUT['CasesPerInvoiceLine'] = np.divide(DF_OUT['Cases'], DF_OUT['InvoiceLine'])\n",
    "    DF_OUT['GP'] = np.divide(DF_OUT['Revenue'], DF_OUT['Cost'])\n",
    "    DF_OUT['GPperBrand'] = np.divide(DF_OUT['GP'], DF_OUT['BrandId'])\n",
    "    DF_OUT['GPperSalesperson'] = np.divide(DF_OUT['GP'], DF_OUT['SalespersonId'])\n",
    "    DF_OUT['BrandsPerSalesperson'] = np.divide(DF_OUT['BrandId'], DF_OUT['SalespersonId'])\n",
    "    \n",
    "    DF_OUT = DF_OUT.merge(customer_attributes, on='CustomerId')\n",
    "    \n",
    "    ffill_cols = ['CasesSoldOnLastSellingDayOfMonth','CasesSoldOnHolidayWeeks',\n",
    "                  'CasesSoldOnLastSellingDayOfMonth_PercentOfTotal','CasesSoldOnHolidayWeeks_PercentOfTotal']\n",
    "    DF_OUT[ffill_cols] = DF_OUT[ffill_cols].fillna(0)\n",
    "    DF_OUT[ffill_cols] = DF_OUT[ffill_cols].replace(np.inf, 0)\n",
    "    DF_OUT['OnPremise'] = DF_OUT['OnPremise'].map({'Y':1,'N':0,'':0})\n",
    "    \n",
    "    DF_OUT.set_index(['Warehouse','CustomerId'], inplace=True)\n",
    "    \n",
    "    return DF_OUT\n",
    "\n",
    "CUSTOMER_SUMMARY = generate_customer_features(path, year=2016)\n",
    "print(CUSTOMER_SUMMARY.head())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Merge in Roadnet data\n",
    "CUSTOMER_SUMMARY.reset_index(drop=False, inplace=True)\n",
    "\n",
    "def get_roadnet_customer_attributes():\n",
    "    new_path = 'C:\\\\Users\\\\pmwash\\\\Desktop\\\\Re-Engineered Reports\\\\Customer Segmentation\\\\Data\\\\Other Data Sources\\\\Service Locations from Roadnet.csv'\n",
    "    dtypes = {'CustomerId':str,'Description':str,'Zip':str,'Coordinate':str,'Priority':str}\n",
    "    RN = pd.read_csv(new_path, header=0, dtype=dtypes)\n",
    "    return RN\n",
    "\n",
    "CUSTOMER_SUMMARY = CUSTOMER_SUMMARY.merge(get_roadnet_customer_attributes(), on='CustomerId', how='left')\n",
    "\n",
    "CUSTOMER_SUMMARY.Coordinate = CUSTOMER_SUMMARY.Coordinate.fillna(0)\n",
    "CUSTOMER_SUMMARY['Latitude'] = [s[s.find('(')+1:s.find(',')] for s in CUSTOMER_SUMMARY.Coordinate.astype(str)]\n",
    "CUSTOMER_SUMMARY['Longitude'] = [s[s.find(',')+1:s.find(')')] for s in CUSTOMER_SUMMARY.Coordinate.astype(str)]\n",
    "CUSTOMER_SUMMARY[['Latitude','Longitude']] = CUSTOMER_SUMMARY[['Latitude','Longitude']].fillna('')\n",
    "CUSTOMER_SUMMARY[['Latitude','Longitude']] = CUSTOMER_SUMMARY[['Latitude','Longitude']].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(CUSTOMER_SUMMARY.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('''\n",
    "Acquire distances of each customer from the warehouses.\n",
    "Estimate distance travelled given number of deliveries.\n",
    "''')\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def get_distances_from_warehouses(CUSTOMER_SUMMARY):\n",
    "    def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "        '''Calculates distance betwen two sets of coordinates'''\n",
    "        lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "        c = 2 * np.arcsin(np.sqrt(a))\n",
    "        km = 6367 * c\n",
    "        mi = .621371 * km\n",
    "        return mi\n",
    "\n",
    "    stl_add = '6701 Southwest Ave, Saint Louis, MO 63143 USA'\n",
    "    kc_add = '550 E 13th Ave, North Kansas City, MO 64116 USA'\n",
    "    col_add = '1502 Business Loop, Columbia, MO 65202 USA'\n",
    "    spfd_add = '455 N Belcrest Ave, Springfield, MO 65802 USA'\n",
    "\n",
    "    addresses = [stl_add, kc_add, col_add, spfd_add]\n",
    "    lat, lon = [], []\n",
    "    for add in addresses:\n",
    "        geolocator = Nominatim()\n",
    "        location = geolocator.geocode(add)\n",
    "        lat.append(location.latitude)\n",
    "        lon.append(location.longitude)\n",
    "\n",
    "    warehouse_locations = pd.DataFrame({'Warehouse':['STL','KC','COL','SPFD'], \n",
    "                                       'Latitude':lat,\n",
    "                                       'Longitude':lon})\n",
    "    warehouse_locations.set_index('Warehouse', inplace=True)\n",
    "    print(warehouse_locations, '\\n\\n')\n",
    "\n",
    "\n",
    "    # CUSTOMER_SUMMARY.reset_index(inplace=True, drop=False)\n",
    "    LAT_STL = CUSTOMER_SUMMARY.loc[CUSTOMER_SUMMARY.Warehouse == 'Saint Louis', 'Latitude'].tolist() \n",
    "    LON_STL = CUSTOMER_SUMMARY.loc[CUSTOMER_SUMMARY.Warehouse == 'Saint Louis', 'Longitude'].tolist()\n",
    "    stl_lat = warehouse_locations.loc[warehouse_locations.index.values=='STL', 'Latitude'].tolist()\n",
    "    stl_lon = warehouse_locations.loc[warehouse_locations.index.values=='STL', 'Longitude'].tolist()\n",
    "\n",
    "    LAT_KC = CUSTOMER_SUMMARY.loc[CUSTOMER_SUMMARY.Warehouse == 'Kansas City', 'Latitude'].tolist() \n",
    "    LON_KC = CUSTOMER_SUMMARY.loc[CUSTOMER_SUMMARY.Warehouse == 'Kansas City', 'Longitude'].tolist()\n",
    "    kc_lat = warehouse_locations.loc[warehouse_locations.index.values=='KC', 'Latitude'].tolist()\n",
    "    kc_lon = warehouse_locations.loc[warehouse_locations.index.values=='KC', 'Longitude'].tolist()\n",
    "\n",
    "    LAT_COL = CUSTOMER_SUMMARY.loc[CUSTOMER_SUMMARY.Warehouse == 'Columbia', 'Latitude'].tolist() \n",
    "    LON_COL = CUSTOMER_SUMMARY.loc[CUSTOMER_SUMMARY.Warehouse == 'Columbia', 'Longitude'].tolist()\n",
    "    col_lat = warehouse_locations.loc[warehouse_locations.index.values=='COL', 'Latitude'].tolist()\n",
    "    col_lon = warehouse_locations.loc[warehouse_locations.index.values=='COL', 'Longitude'].tolist()\n",
    "\n",
    "    LAT_SPFD = CUSTOMER_SUMMARY.loc[CUSTOMER_SUMMARY.Warehouse == 'Springfield', 'Latitude'].tolist() \n",
    "    LON_SPFD = CUSTOMER_SUMMARY.loc[CUSTOMER_SUMMARY.Warehouse == 'Springfield', 'Longitude'].tolist()\n",
    "    spfd_lat = warehouse_locations.loc[warehouse_locations.index.values=='SPFD', 'Latitude'].tolist()\n",
    "    spfd_lon = warehouse_locations.loc[warehouse_locations.index.values=='SPFD', 'Longitude'].tolist()\n",
    "\n",
    "    STL_DIST = [haversine_distance(stl_lat,stl_lon,lat,lon) for lat,lon in zip(LAT_STL, LON_STL)]\n",
    "    KC_DIST = [haversine_distance(kc_lat,kc_lon,lat,lon) for lat,lon in zip(LAT_KC, LON_KC)]\n",
    "    COL_DIST = [haversine_distance(col_lat,col_lon,lat,lon) for lat,lon in zip(LAT_COL, LON_COL)]\n",
    "    SPFD_DIST = [haversine_distance(spfd_lat,spfd_lon,lat,lon) for lat,lon in zip(LAT_SPFD, LON_SPFD)]\n",
    "\n",
    "    CUSTOMER_SUMMARY.loc[CUSTOMER_SUMMARY.Warehouse == 'Saint Louis', 'DistanceFromWarehouse'] = STL_DIST\n",
    "    CUSTOMER_SUMMARY.loc[CUSTOMER_SUMMARY.Warehouse == 'Kansas City', 'DistanceFromWarehouse'] = KC_DIST\n",
    "    CUSTOMER_SUMMARY.loc[CUSTOMER_SUMMARY.Warehouse == 'Columbia', 'DistanceFromWarehouse'] = COL_DIST\n",
    "    CUSTOMER_SUMMARY.loc[CUSTOMER_SUMMARY.Warehouse == 'Springfield', 'DistanceFromWarehouse'] = SPFD_DIST\n",
    "    \n",
    "    importance_map = {np.nan:0,'Lowest':1,'Lower':2,'Normal':3,'Higher':4,'Highest':5,'Must Make Service Windows':6}\n",
    "    CUSTOMER_SUMMARY['ServiceWindowImportance'] = CUSTOMER_SUMMARY['Service Window Importance'].map(importance_map)\n",
    "    \n",
    "    return CUSTOMER_SUMMARY\n",
    "\n",
    "CUSTOMER_SUMMARY = get_distances_from_warehouses(CUSTOMER_SUMMARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     6294\n",
      "11    1794\n",
      "6      803\n",
      "13     350\n",
      "9      128\n",
      "2      126\n",
      "10      80\n",
      "1       58\n",
      "8       33\n",
      "14      29\n",
      "7       20\n",
      "12       9\n",
      "4        9\n",
      "3        5\n",
      "5        1\n",
      "Name: cluster, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "cluster = KMeans(n_clusters=15, max_iter=10000)\n",
    "cluster_cols = ['Invoice','Cases','BrandId','AvgDaysBetweenInvoices','AllottedWeeklyDeliveryDays','OnPremise',\n",
    "               'CasesPerUniqueBrand','CasesPerInvoiceLine','CasesPerUniqueSalesperson','CasesPerInvoice','GP',\n",
    "               'GPperSalesperson','GPperBrand','BrandsPerSalesperson','DistanceFromWarehouse','ServiceWindowImportance']\n",
    "CUSTOMER_SUMMARY[cluster_cols] = CUSTOMER_SUMMARY[cluster_cols].fillna(0)\n",
    "CUSTOMER_SUMMARY[cluster_cols] = CUSTOMER_SUMMARY[cluster_cols].replace(np.inf, 0)\n",
    "CUSTOMER_SUMMARY['cluster'] = cluster.fit_predict(CUSTOMER_SUMMARY[cluster_cols])\n",
    "#CUSTOMER_SUMMARY['cluster'] = CUSTOMER_SUMMARY['cluster'].astype(str)\n",
    "print(CUSTOMER_SUMMARY.cluster.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "CUSTOMER_SUMMARY.reset_index(drop=False, inplace=True)\n",
    "#CUSTOMER_SUMMARY.to_csv('C:\\\\Users\\\\pmwash\\\\Desktop\\\\Disposable Docs\\\\CUSTOMER SUMMARY 2016 SEGMENTATION.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
