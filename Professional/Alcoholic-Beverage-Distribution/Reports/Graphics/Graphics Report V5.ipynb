{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphics Report V5\n",
    "\n",
    "## Paul M. Washburn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import read_table\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "import re\n",
    "import time # add decorator to time functions\n",
    "from collections import OrderedDict\n",
    "from functools import wraps\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "\n",
    "pct_change = lambda new, old: (new - old) / old\n",
    "len_unique = lambda x: len(pd.unique(x))\n",
    "\n",
    "def timing_function(some_function):\n",
    "    '''\n",
    "    Decorator function.  Outputs the time a function takes to execute.\n",
    "    '''\n",
    "    @wraps(some_function)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        t1 = time.time()\n",
    "        result = some_function(*args, **kwargs)\n",
    "        t2 = time.time()\n",
    "        time_elapsed = round((t2 - t1), 2)\n",
    "        print('Runtime: ' + str(time_elapsed) + ' seconds')\n",
    "        return result\n",
    "    \n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make sure Franky shows up (in salesperson field) as \"TOCCO, FRANKY\"\n"
     ]
    }
   ],
   "source": [
    "print('Make sure Franky shows up (in salesperson field) as \"TOCCO, FRANKY\"')\n",
    "active_designers = ['Wilhoit, Katie','Wright, Paige','Whited, Phillip D', 'Tocco, Franky']\n",
    "active_designer_salespeople = ['WILHOIT, KATIE','WRIGHT, PAIGE','WHITED, PHILIP D.', 'TOCCO, FRANKY']\n",
    "\n",
    "def fetch_current_month_year():\n",
    "    '''\n",
    "    Fetches month & year based on current date.\n",
    "    '''\n",
    "    this_mo = dt.now().replace(month=last_mo).strftime('%B')\n",
    "    this_yr = dt.now().year\n",
    "    time_dict = {'this_yr': this_yr, 'this_mo': this_mo}\n",
    "    \n",
    "    return time_dict\n",
    "\n",
    "@timing_function\n",
    "def preprocess_raw_data():\n",
    "    '''\n",
    "    Pre-processes information from Diver sent on Mondays via email.\n",
    "    '''\n",
    "    df = read_table('N:/Operations Intelligence/Monthly Reports/Graphics/Raw Data/POSTER Detail_dump.txt', \n",
    "                    engine='python', doublequote=False, header=0, sep=',')\n",
    "\n",
    "    col_names = {'ID':'ID',\n",
    "                'DVMKET':'Warehouse',\n",
    "                'DVJOBID':'JobId',\n",
    "                'DVJOBNAME':'JobName',\n",
    "                'DVREPRNT':'Reprint',\n",
    "                'DVJBSTAT':'JobStatus',\n",
    "                'DVCUSTNUM':'CustomerId',\n",
    "                'DVCUSTN':'Customer',\n",
    "                'CHINVDAT':'InvoiceDate',\n",
    "                'DVITMID':'ItemId',\n",
    "                'DVITMCAT':'ItemCategory',\n",
    "                'DVITMDSC':'ItemDescription',\n",
    "                'DVITMWTH':'ItemWidth',\n",
    "                'DVITMHGT':'ItemHeight',\n",
    "                'DVQTYORD':'QtyOrdered',\n",
    "                'DVMULTPL':'GraphicsJobOption', #check with Rachel for semantics\n",
    "                'DVLINAMT':'JobTotalCost',\n",
    "                'DVNMBMN':'NonMajorBrandsMentions', #verify with Rachel\n",
    "                'DVJOBSTR':'AccessoryPrintBanner',\n",
    "                'DVSUPP':'SupplierId',\n",
    "                'DVSUPNAM':'Supplier',\n",
    "                'DVBRNDID':'ProductId',\n",
    "                'DVBRNDNM':'Product',\n",
    "                'DVSBRNID':'BrandId',\n",
    "                'DVSBRNNM':'Brand',\n",
    "                'DVMBMENT':'MajorBrandsMentions', #verify with Rachel\n",
    "                'DVCBRATE':'ChargebackRate',\n",
    "                'DVDISTCS':'PosterPrice', #verify with Rachel\n",
    "                'DVCBAMT':'ChargebackAmount',\n",
    "                'DVCBTOTL':'ChargebackTotal',\n",
    "                'DVSPNBR':'SalespersonId',\n",
    "                'DVSPNAME':'Salesperson',\n",
    "                'DVIMAGE':'DVIMAGE',\n",
    "                'DVAPRDIR':'Director',\n",
    "                'DVBRND':'DVBRND',#DVSBRNID\n",
    "                'DVITMNUM':'unsure11',\n",
    "                'DVITMOPT':'DVITMOPT',\n",
    "                'DVCBOVRD':'BrandMentionOverride',\n",
    "                'DVGRPHDS':'Designer',\n",
    "                'DVGRPHDF':'User'}\n",
    "\n",
    "    df.rename(columns=col_names, inplace=True)\n",
    "    df.Warehouse = df.Warehouse.astype(str)\n",
    "    df.Warehouse = df.Warehouse.map({'1':'Kansas City', '2':'Saint Louis', '3':'Columbia', '5':'Springfield'})\n",
    "    df.set_index('ID', inplace=True)\n",
    "    df.drop(labels=['DVIMAGE','ItemWidth','ItemHeight','DVITMOPT'], axis=1, inplace=True)\n",
    "\n",
    "    df.to_csv('N:/Operations Intelligence/Monthly Reports/Graphics/Raw Data/renamed raw data.csv', index=False)\n",
    "    \n",
    "    print('Data re-written to disk.')\n",
    "    \n",
    "def generate_calendar(year):\n",
    "    '''\n",
    "    Generates calendar by day with relevant information.\n",
    "    '''\n",
    "    from pandas.tseries.offsets import YearEnd\n",
    "    from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "    \n",
    "    start_date = pd.to_datetime('1/1/'+str(year))\n",
    "    end_date = start_date + YearEnd()\n",
    "    DAT = pd.date_range(str(start_date), str(end_date), freq='D')\n",
    "    WK = [d.strftime('%U') for d in DAT]\n",
    "    MO = [d.strftime('%B') for d in DAT]\n",
    "    holidays = USFederalHolidayCalendar().holidays(start=start_date, end=end_date)\n",
    "\n",
    "    cal = pd.DataFrame({'Date':DAT, 'WeekNumber':WK, 'Month':MO})\n",
    "    \n",
    "    cal['Year'] = [format(d, '%Y') for d in DAT]\n",
    "    cal['Weekday'] = [format(d, '%A') for d in DAT]\n",
    "    cal['DOTM'] = [format(d, '%d') for d in DAT]\n",
    "    cal['IsWeekday'] = cal.Weekday.isin(['Monday','Tuesday','Wednesday','Thursday','Friday'])\n",
    "    cal['IsProductionDay'] = cal.Weekday.isin(['Tuesday','Wednesday','Thursday','Friday'])\n",
    "    last_biz_day = [str(format(dat, '%Y-%m-%d')) for dat in pd.date_range(start_date, end_date, freq='BM')]\n",
    "    cal['LastSellingDayOfMonth'] = [dat in last_biz_day for dat in cal['Date'].astype(str)]\n",
    "\n",
    "    cal.loc[cal.WeekNumber.isin(['00','01','02','03','04','05','06','07','08','09','50','51','52','53']), 'Season'] = 'Winter'\n",
    "    cal.loc[cal.WeekNumber.isin(['10','11','12','13','14','15','16','17','18','19','20','21','22']), 'Season'] = 'Spring'\n",
    "    cal.loc[cal.WeekNumber.isin(['23','24','25','26','27','28','29','30','31','32','33','34','35']), 'Season'] = 'Summer'\n",
    "    cal.loc[cal.WeekNumber.isin(['36','37','38','39','40','41','42','43','44','45','46','47','48','49']), 'Season'] = 'Autumn'\n",
    "    cal['Holiday'] = cal.Date.isin(holidays)\n",
    "    cal['HolidayWeek'] = cal['Holiday'].rolling(window=7,center=True,min_periods=1).sum()\n",
    "    cal['ShipWeek'] = ['A' if int(wk) % 2 == 0 else 'B' for wk in WK]\n",
    "\n",
    "    cal.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_raw_data()\n",
    "\n",
    "df = pd.read_csv('N:/Operations Intelligence/Monthly Reports/Graphics/Raw Data/renamed raw data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing_function\n",
    "def munge_data(df):\n",
    "    '''\n",
    "    Cleans up raw data to put into useable format.\n",
    "    '''\n",
    "    # concatenate fields to identify unique jobs and items\n",
    "    df['JobItemBrandId'] = df.JobId.astype(str) + '_' + df.ItemId.astype(str) + '_' + df.BrandId.astype(str)\n",
    "    df['JobItemId'] = df['JobId'].astype(str) + '_' + df.ItemId.astype(str)\n",
    "    \n",
    "    # sort dataframe in decreasing order by length of \"JobStatus\" field\n",
    "    sorter = df.JobStatus.str.len().sort_values(ascending=False).index\n",
    "    df = df.reindex(sorter)\n",
    "    \n",
    "    # mark dates etc\n",
    "    df['InvoiceDate'] = dat = pd.to_datetime(df.InvoiceDate)\n",
    "    df['InvoiceWeek'] = [d.strftime('%U') for d in dat]\n",
    "    df['InvoiceMonth'] = [d.strftime('%B') for d in dat]\n",
    "    df['InvoiceYear'] = [d.strftime('%Y') for d in dat]\n",
    "    df['Weekday'] = [format(d, '%A') for d in dat]\n",
    "    df['DOTM'] = [format(d, '%d') for d in dat]\n",
    "    \n",
    "    # extract profit from price/chargeback\n",
    "    print('Verify veracity:  chargeback - poster_price = profit')\n",
    "    df['Profit'] = np.subtract(df.ChargebackTotal.astype(np.float64), df.PosterPrice.astype(np.float64))\n",
    "    \n",
    "    # fix data errors that should've never happened\n",
    "    df['Designer'] = [d if d != 'FRANKY TOCCO' else 'Tocco, Franky' for d in df.Designer.tolist()]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = munge_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stage_name(job_status):\n",
    "    '''\n",
    "    Takes list of job statuses (raw) and removes dates, returning\n",
    "    only the title of each stage.\n",
    "    '''\n",
    "    # specify lambda functions\n",
    "    drop_dates = lambda x: re.sub(r\"\\\\s*\\\\([^\\\\)]+\\\\)\", '', x)\n",
    "    drop_spaces = lambda x: re.sub(r'[[:space:]]', '', x)\n",
    "    drop_second_element = lambda x: str(x).split(\" (\")[0].replace(' ', '')\n",
    "\n",
    "    # do work\n",
    "    job_status = [drop_dates(s) for s in job_status]\n",
    "    job_status = [drop_spaces(s) for s in job_status]\n",
    "    job_status = [drop_second_element(s) for s in job_status]\n",
    "    \n",
    "    return job_status\n",
    "\n",
    "\n",
    "def stage_dates_by_job(job_status, job_ids):\n",
    "    '''\n",
    "    Extracts stages and dates into a dict(dict()) item\n",
    "    by job id number.\n",
    "    '''\n",
    "    # specify lambda functions\n",
    "    munge_date = lambda x: format(dt.strptime(x, '%b %d %Y %I:%M%p'), '%Y-%m-%d %H:%M')\n",
    "\n",
    "    # split each element in job status at the comma \n",
    "    job_status_split = [str(s).split(',') for s in job_status]\n",
    "\n",
    "    # derive stages for each job\n",
    "    job_status_dict = dict()\n",
    "    for job, job_id in zip(job_status_split, job_ids):\n",
    "        # get dates\n",
    "        dat = [str(s).split('(')[1].replace(')', '') for s in job]\n",
    "        dat = [munge_date(d) for d in dat]\n",
    "\n",
    "        # get job status names\n",
    "        sts = extract_stage_name(job)\n",
    "\n",
    "        # save to dict\n",
    "        job_status_dict[job_id] = dict(zip(sts, dat))\n",
    "\n",
    "    return job_status_dict\n",
    "\n",
    "# send job status & job ids to list\n",
    "job_status = df.JobStatus.tolist()\n",
    "job_ids = df.JobId.tolist()\n",
    "\n",
    "job_status_dict = stage_dates_by_job(job_status, job_ids)\n",
    "\n",
    "@timing_function\n",
    "def compile_all_job_stages(job_status_dict):\n",
    "    '''\n",
    "    Calls the functions above.\n",
    "    '''\n",
    "    job_stage_list = list()\n",
    "    for item in job_status_dict.items():\n",
    "        js_dict = item[1]\n",
    "        js_dict.update({'JobId': item[0]})\n",
    "        job_stage_list.append(js_dict)\n",
    "        \n",
    "    job_stage_df = pd.DataFrame(job_stage_list)\n",
    "    job_stage_df = job_stage_df.sort_values(['AssembledandShipped', 'Incomplete'], ascending=False)\n",
    "    \n",
    "    return job_stage_df\n",
    "\n",
    "job_summary_df = compile_all_job_stages(job_status_dict)\n",
    "\n",
    "df = job_summary_df.merge(df, on='JobId', how='outer')\n",
    "\n",
    "# sort dataframe\n",
    "sort_cols = ['AssembledandShipped', 'Incomplete', 'JobId']\n",
    "df.sort_values(sort_cols, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_reprint_redesign(df):\n",
    "    '''\n",
    "    Identifies reprints and redesigns by generating a boolean column.\n",
    "    '''\n",
    "    # reprints & redesigns\n",
    "    df['Reprint'] = df.Reprint.astype(bool)\n",
    "    df['Redesign'] = ~df.AwaitingArtworkRedesign.isnull()\n",
    "\n",
    "    return df\n",
    "\n",
    "def id_menus_accessories(df):\n",
    "    '''\n",
    "    Identifies menus and accessories by generating a boolean column.\n",
    "    '''\n",
    "    # mark menus and accessories\n",
    "    accessories = ['Menu Books','Table Top Wrap','TT A-Frame Holder','TT A-Frame Holder (Holder Only)', \n",
    "                   'TT Acrylic Stand','TT Acrylic Stand (Stand Only)','TT Flip Stand','TT Flip Stand (Stand Only)',\n",
    "                   'Vivid Board - Dry Erase','Vivid Board - Dry Erase','Light Box']\n",
    "    df['Accessory'] = [a in accessories for a in df.ItemCategory.tolist()]\n",
    "\n",
    "    menus = ['Menu Books','Drink List','Folded Drink List','Tri-Fold Drink List',\n",
    "             'Folded Menu Cards','Menu Card - Small Format (QTY <- Total Pages)']\n",
    "    df['Menu'] = [m in menus for m in df.ItemCategory.tolist()]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df = id_reprint_redesign(df)\n",
    "df = id_menus_accessories(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def drop_cancelled_jobs(df):\n",
    "    '''\n",
    "    Drops cancelled jobs and displays some summary information.\n",
    "    '''\n",
    "    df_cancelled = df.loc[(~df.Cancelled.isnull()) & (df.InvoiceYear == dt.now().year)]\n",
    "    \n",
    "    grp_cols = ['Warehouse', 'Salesperson', 'Customer']\n",
    "    agg_funcs = {'JobId': len_unique, 'Profit': np.sum}\n",
    "    df_cancelled = df_cancelled.groupby(grp_cols).agg(agg_funcs)\n",
    "    \n",
    "    if len(df_cancelled.JobId.tolist()) > 0:\n",
    "        print('This Year Cancelled Job Summary: \\n')\n",
    "        print(df_cancelled)\n",
    "    else:\n",
    "        print('No Jobs Cancelled This Year.')\n",
    "    \n",
    "    return df.loc[df.Cancelled.isnull()]\n",
    "\n",
    "df = drop_cancelled_jobs(df)\n",
    "\n",
    "# save intermediate data\n",
    "df.to_csv('C:/Users/pmwash/Desktop/Re-Engineered Reports/Graphics/intermediate_graphics_data_dump_diver.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turnaround_by_job(job_summary_df):\n",
    "    '''\n",
    "    Returns a dict object with {'JobId': 'Turnaround'} for \n",
    "    mapping back into original dataframe.\n",
    "    '''\n",
    "    job_summary_df.fillna('', inplace=True)\n",
    "\n",
    "    # derive turnaround by job id\n",
    "    datetime_cols = [col for col in job_summary_df.columns.tolist() if col != 'JobId']\n",
    "    job_summary_df[datetime_cols] = job_summary_df[datetime_cols].apply(pd.to_datetime)\n",
    "    job_summary_df['Turnaround'] = np.subtract(job_summary_df.AssembledandShipped, job_summary_df.Incomplete)\n",
    "\n",
    "    # send turnaround to dict for mapping into df\n",
    "    turnaround_dict = dict(zip(job_summary_df.JobId.tolist(), job_summary_df.Turnaround.tolist()))\n",
    "\n",
    "    return turnaround_dict, job_summary_df\n",
    "    \n",
    "turnaround_dict, job_summary_df = turnaround_by_job(job_summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
