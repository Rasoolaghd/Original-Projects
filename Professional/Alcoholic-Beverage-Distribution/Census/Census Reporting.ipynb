{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Census Reporting \n",
    "Due Dates \n",
    "2/7 for 1/15-1/21, \n",
    "5/9 for 4/16-4/22, \n",
    "8/8 for 7/16-7/22, \n",
    "11/7 for 10/15-10/21\n",
    "\n",
    "Run pw_census1 and pw_census2 for the date ranges specified by the document\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "\n",
    "path = 'C:\\\\Users\\\\pmwash\\\\Desktop\\\\Re-Engineered Reports\\\\Census\\\\'\n",
    "\n",
    "def read_combine_source(path):\n",
    "    prd1 = pd.read_csv(path+'pw_census1.csv', header=0, dtype={'PPROD#':int,'PCLAS@':int,'PQTYPC':int,'PWEIGH':np.float64})\n",
    "    prd1.rename(columns={'PPROD#':'ProductId','PCLAS@':'x','PQTYPC':'xx','PWEIGH':'WeightPerCase'}, inplace=True)\n",
    "    prd1.drop(['x','xx'], axis=1, inplace=True)\n",
    "    \n",
    "    mtc1 = pd.read_csv(path+'pw_census2.csv', header=0, \n",
    "                       dtype={'#MCMP':int,'#MIVDT':str,'#MIVND':str,\n",
    "                              '#MLIN#':str,'#MCUS#':int,'#MINP#':int,\n",
    "                              '#MCLA@':int,'#MEXT$':np.float64,'NONSTDCASE':np.float64,\n",
    "                              'CCITY':str,'CSTATE':str,'CZIP@':str})\n",
    "    new_namz = {'#MCMP':'Company','#MIVDT':'Date','#MIVND':'Invoice','#MLIN#':'Line','#MCUS#':'CustomerId','#MINP#':'ProductId',\n",
    "               '#MCLA@':'Class','#MEXT$':'ExtCost','NONSTDCASE':'NonStdCases','CCITY':'City','CSTATE':'State','CZIP@':'Zip'}\n",
    "    mtc1.rename(columns=new_namz, inplace=True)\n",
    "    \n",
    "    combined = mtc1.merge(prd1, on='ProductId', how='outer')\n",
    "    combined = combined[[len(dat) == 7 for dat in combined.Date.astype(str)]]\n",
    "    combined.dropna(axis=0, how='all', thresh=len(combined.columns), inplace=True)\n",
    "    \n",
    "    combined.Company = combined.Company.map({1:'Kansas City',2:'Saint Louis',3:'Columbia',5:'Springfield'})\n",
    "    combined['InvoiceLine'] = [str(i)+'_'+str(l) for i,l in zip(combined.Invoice, combined.Line)]\n",
    "    combined['Weight'] = np.multiply(combined.NonStdCases, combined.WeightPerCase)\n",
    "    \n",
    "    combined['RefrigeratedDelivery'] = ['Y' if p_clas in [86,87,88] else 'N' for p_clas in combined.Class.tolist()]\n",
    "    \n",
    "    product_class_map = {10:'08320', 25:'08320', 50:'08200', 51:'08200', 53:'08200',\n",
    "                        55:'08200', 58:'08200', 59:'08200', 70:'08320',\n",
    "                        80:'08100', 84:'08100', 85:'08100', 86:'08100', \n",
    "                        87:'08100', 88:'08100', 90:'07899', 91:'07899',\n",
    "                        92:'07811', 95:'08320', 99:'08320'}\n",
    "    combined.Class = combined.Class.map(product_class_map)\n",
    "    \n",
    "    def as400_date(dat):\n",
    "        try:\n",
    "            d = dt.date(dt.strptime(dat[-6:], '%y%m%d'))\n",
    "        except ValueError:\n",
    "            d = dt.date(dt.strptime('1990909', '%y%m%d'))\n",
    "        return d\n",
    "    \n",
    "    combined.Date = [as400_date(dat) for dat in combined.Date.astype(str).tolist()]\n",
    "    combined.sort_values(['Company','Date'], inplace=True)\n",
    "    combined.drop(['WeightPerCase','Line'], axis=1, inplace=True)\n",
    "    combined = combined[combined.ExtCost > 0]\n",
    "\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def process_combined(combo, company):\n",
    "    combo = combo[combo.Company == company]\n",
    "    combo['CommodityCode'] = combo.loc[combo.groupby(['Invoice'])['Weight'].transform(max) == combo.Weight, 'Class']\n",
    "    combo.sort_values(['Invoice','CommodityCode'], inplace=True)\n",
    "    combo.CommodityCode.fillna(method='ffill', inplace=True)\n",
    "    comm_desc = {'07891':'Ice & Other Non-Alcoholic','08100':'Beer','08200':'Wine & Other Fermented Beverages',\n",
    "                '08320':'Spirits, Liqueurs, & Other Spirituous Beverages (<80% ABV)'}\n",
    "    combo['CommodityDescription'] = combo.CommodityCode.map(comm_desc)\n",
    "    combo['Month'] = [format(dat, '%m') for dat in combo.Date]\n",
    "    combo['Day'] = [format(dat, '%d') for dat in combo.Date]\n",
    "    \n",
    "    combo.sort_values(['Company','Invoice','InvoiceLine'], inplace=True)\n",
    "    combo.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    grp_cols = ['Invoice','Month','Day','CommodityCode','CommodityDescription','RefrigeratedDelivery','City','State','Zip']\n",
    "    combo_agg = pd.DataFrame(combo.groupby(grp_cols)[['ExtCost','Weight']].sum()).reset_index(drop=False)\n",
    "    combo_agg['Hazardous'] = 'N'\n",
    "    combo_agg['ModeOfTransport'] = '2'\n",
    "    combo_agg['Export'] = 'N'\n",
    "    reordered = ['Invoice','Month','Day','ExtCost','Weight','CommodityCode','CommodityDescription',\n",
    "                 'RefrigeratedDelivery','Hazardous','City','State','Zip','ModeOfTransport','Export']\n",
    "    combo_agg = combo_agg[reordered]\n",
    "\n",
    "    return combo_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pmwash\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\pmwash\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\pmwash\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n",
      "C:\\Users\\pmwash\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\pmwash\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\pmwash\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\pmwash\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N:/Operations Intelligence/Census/Q1_2017_Saint Louis_Census Survey.xlsx  successfully written to file.\n",
      "\n",
      "        Total Count of Shipments for Saint Louis = 4513\n",
      "        \n",
      "        Total Dollars of Shipments for Saint Louis = 2424227.11 \n",
      "        \n",
      "N:/Operations Intelligence/Census/Q1_2017_Springfield_Census Survey.xlsx  successfully written to file.\n",
      "\n",
      "        Total Count of Shipments for Springfield = 1028\n",
      "        \n",
      "        Total Dollars of Shipments for Springfield = 559250.62 \n",
      "        \n",
      "N:/Operations Intelligence/Census/Q1_2017_Columbia_Census Survey.xlsx  successfully written to file.\n",
      "\n",
      "        Total Count of Shipments for Columbia = 926\n",
      "        \n",
      "        Total Dollars of Shipments for Columbia = 417781.77 \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "def export_census_data(combo, path, quarter_year, report_every):\n",
    "    locations_to_generate = ['Saint Louis','Springfield','Columbia']\n",
    "    out_path = 'N:/Operations Intelligence/Census/'\n",
    "    for loc in locations_to_generate:\n",
    "        f_name = out_path + str(quarter_year) + '_' + str(loc) + '_Census Survey.xlsx' \n",
    "        data = process_combined(combo, company=loc)\n",
    "        print(f_name, ' successfully written to file.')\n",
    "        print('''\n",
    "        Total Count of Shipments for %s = %i\n",
    "        \n",
    "        Total Dollars of Shipments for %s = %.2f \n",
    "        ''' %(loc, len(data.Invoice), loc, data.ExtCost.sum()))\n",
    "        data = data[data.index % report_every == True]\n",
    "        data.to_excel(f_name, sheet_name=str(loc))\n",
    "    return None\n",
    "        \n",
    "export_census_data(read_combine_source(path), path, quarter_year='Q1_2017', report_every=60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
