---
title: "<b><h1>Inbound Shipments</h1></b>"
subtitle: "<b><small>Capacity & Constraints</small></b>"
author: "<small>Paul M. Washburn - Operations Analyst</small>"
date: "<small>December 2016</small>"
output: revealjs::revealjs_presentation#html_document #ioslides_presentation #slidy_presentation #beamer_presentation #revealjs::revealjs_presentation
theme: solarized
center: true
fig_width: 10
fig_height: 5
fig_caption: true
widescreen: true
transition: slide
autosize: true
---

```{r setup, include=FALSE}
if (Sys.getenv("JAVA_HOME")!="")
  Sys.setenv(JAVA_HOME="")
## Load Libraries
library(ggplot2)
library(plotly)
library(scales)
library(dplyr)
library(zoo)
library(plotly)
library(lubridate)
library(plyr)
library(DT)
library(tidyr)
source('C:/Users/pmwash/Desktop/R_files/Data Input/Helper.R')

## Pre-process data
DAILY_SUMMARY = read.csv('C:/Users/pmwash/Desktop/R_files/Data Input/SUMMARY INBOUND SHIPMENTS.csv', header=TRUE)
DAILY_SUMMARY$Weekday = factor(DAILY_SUMMARY$Weekday, levels=c('Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday')) 
DAILY_SUMMARY = DAILY_SUMMARY %>% filter(CasesPerPOLine <= 1000)
DAILY_SUMMARY$IsWeekend = DAILY_SUMMARY$Weekday %in% c('Saturday','Sunday')
DAILY_SUMMARY$IsMonday = DAILY_SUMMARY$Weekday %in% c('Monday')


## MARK THRESHOLDS FOR VIOLATIONS
THRESH = 0.95

KC_MAX_CASESIN = ddply(DAILY_SUMMARY, 'Warehouse', summarise, Percentile=quantile(Cases_Received, THRESH))[1,2]
STL_MAX_CASESIN = ddply(DAILY_SUMMARY, 'Warehouse', summarise, Percentile=quantile(Cases_Received, THRESH))[2,2]

KC_MAX_POLINES = ddply(DAILY_SUMMARY, 'Warehouse', summarise, Percentile=quantile(PO_._Line_Number, THRESH))[1,2]
STL_MAX_POLINES = ddply(DAILY_SUMMARY, 'Warehouse', summarise, Percentile=quantile(PO_._Line_Number, THRESH))[2,2]

max_cs = round(c(STL_MAX_CASESIN, KC_MAX_CASESIN))
max_po = round(c(STL_MAX_POLINES, KC_MAX_POLINES))
thresh_df = data.frame(cbind(max_cs, max_po))
row.names(thresh_df) = c('STL', 'KC')
names(thresh_df) = c('95th Percentile - Cases Received', '95th Percentile - PO Lines Received')

LINES = DAILY_SUMMARY$PO_._Line_Number
CASES = DAILY_SUMMARY$Cases_Received
WHSE = DAILY_SUMMARY$Warehouse

DAILY_SUMMARY$OPERATIONAL_THRESHOLD_EXCEEDED = 
  ifelse(WHSE == 'Saint Louis' & (CASES >= STL_MAX_CASESIN | LINES >= STL_MAX_POLINES)==T, TRUE,
       ifelse(WHSE == 'Kansas City' & (CASES >= KC_MAX_CASESIN | LINES >= KC_MAX_POLINES)==T, TRUE, FALSE) )




#PAIR PLOTS FOR CORRELATIONS AMONGS PREDICTORS
panel.cor <- function(x, y, digits=2, cex.cor)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(0, 1, 0, 1))
  r <- abs(cor(x, y))
  txt <- format(c(r, 0.123456789), digits=digits)[1]
  test <- cor.test(x,y)
  Signif <- ifelse(round(test$p.value,3)<0.050,"Significant at\n p < 0.050",paste("p=",round(test$p.value,3)))  
  text(0.5, 0.25, paste("r=",txt))
  text(.5, .75, Signif)
}

panel.smooth<-function (x, y, col = "blue", bg = NA, pch = 18, 
                        cex = 0.8, col.smooth = "red", span = 2/3, iter = 3, ...) 
{
  points(x, y, pch = pch, col = col, bg = bg, cex = cex)
  ok <- is.finite(x) & is.finite(y)
  if (any(ok)) 
    lines(stats::lowess(x[ok], y[ok], f = span, iter = iter), 
          col = col.smooth, ...)
}

panel.hist <- function(x, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(usr[1:2], 0, 1.5) )
  h <- hist(x, plot = FALSE)
  breaks <- h$breaks; nB <- length(breaks)
  y <- h$counts; y <- y/max(y)
  rect(breaks[-nB], 0, breaks[-1], y, col="cyan", ...)
}


stl = DAILY_SUMMARY %>% filter(Warehouse=='Saint Louis')
stl = stl[, c(7:11,14)]
stl_pairs = pairs(stl, lower.panel=panel.cor, diag.panel=panel.hist, upper.panel=panel.smooth, main='Inbound Shipment Correlations in STL')


kc = DAILY_SUMMARY %>% filter(Warehouse=='Kansas City')
kc = kc[, c(7:11,14)]
kc_pairs = pairs(kc, lower.panel=panel.smooth, diag.panel=panel.hist, upper.panel=panel.cor, main='Inbound Shipment Correlations in KC')



#POLINES - DAILY BY MONTH AND WAREHOUSE
p = ggplot(data=DAILY_SUMMARY, aes(x=factor(Month), y=PO_._Line_Number, group=Year))
DAILY_POLINES_PLOT = p +
  geom_boxplot(aes(fill=Warehouse, group=Month, alpha=0.7)) +
  facet_grid(Warehouse ~ Year, scales='free_y') +
  geom_jitter(alpha=0.2, size=1) +
  theme(legend.position='none', axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title='Daily PO Lines Received by House/Month', x='Month', y='PO Lines') +
  scale_y_continuous(labels=comma) +
  geom_hline(yintercept=STL_MAX_POLINES, colour='blue', size=2, alpha=0.1) +
  geom_hline(yintercept=KC_MAX_POLINES, colour='red', size=2, alpha=0.1)
#DAILY_POLINES_PLOT

#POLINES - DAILY BY WEEKDAY AND WAREHOUSE
p = ggplot(data=DAILY_SUMMARY, aes(x=factor(Weekday), y=PO_._Line_Number, group=Year))
WEEKDAY_POLINES_PLOT = p +
  geom_boxplot(aes(fill=Warehouse, group=Weekday, alpha=0.7)) +
  facet_grid(Warehouse ~ Year, scales='free_y') +
  geom_jitter(alpha=0.2, size=1) +
  theme(legend.position='none', axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title='Daily PO Lines Received by House/Weekday', x='Month', y='PO Lines') +
  scale_y_continuous(labels=comma) +
  geom_hline(yintercept=STL_MAX_POLINES, colour='blue', size=2, alpha=0.1) +
  geom_hline(yintercept=KC_MAX_POLINES, colour='red', size=2, alpha=0.1)
#WEEKDAY_POLINES_PLOT



#CASES - DAILY BY MONTH AND WAREHOUSE
p = ggplot(data=DAILY_SUMMARY, aes(x=factor(Month), y=Cases_Received, group=Year))
DAILY_CASES_PLOT = p +
  geom_boxplot(aes(fill=Warehouse, group=Month, alpha=0.7)) +
  facet_grid(Warehouse ~ Year, scales='free_y') +
  geom_jitter(alpha=0.2, size=1) +
  theme(legend.position='none', axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title='Daily Cases Received by House/Month', x='Month', y='PO Lines') +
  scale_y_continuous(labels=comma) +
  geom_hline(yintercept=STL_MAX_CASESIN, colour='blue', size=2, alpha=0.1) +
  geom_hline(yintercept=KC_MAX_CASESIN, colour='red', size=2, alpha=0.1)
#DAILY_CASES_PLOT

#CASES - DAILY BY WEEKDAY AND WAREHOUSE
p = ggplot(data=DAILY_SUMMARY, aes(x=factor(Weekday), y=Cases_Received, group=Year))
WEEKDAY_CASES_PLOT = p +
  geom_boxplot(aes(fill=Warehouse, group=Weekday, alpha=0.7)) +
  facet_grid(Warehouse ~ Year, scales='free_y') +
  geom_jitter(alpha=0.2, none=1) +
  theme(legend.position='none', axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(title='Daily Cases Received by House/Weekday', x='Weekday', y='Cases Received') +
  scale_y_continuous(labels=comma) +
  geom_hline(yintercept=STL_MAX_CASESIN, colour='blue', size=2, alpha=0.1) +
  geom_hline(yintercept=KC_MAX_CASESIN, colour='red', size=2, alpha=0.1)
#WEEKDAY_CASES_PLOT
#ggplotly(WEEKDAY_CASES_PLOT)



#SCATTERPLOT - PO LINES AND CASES RECEIVED
library(reshape2)
for_merge = DAILY_SUMMARY[,c('Warehouse','PO_._Line_Number','Cases_Received',
                             'CasesPerPOLine')]
for_merge$CasesReceivedSTL = ifelse(for_merge$Warehouse == 'Kansas City', NA, for_merge$Cases_Received)
for_merge$CasesReceivedKC = ifelse(for_merge$Warehouse == 'Kansas City', for_merge$Cases_Received, NA)
for_merge$Cases_Received = NULL

names(for_merge) = c('Warehouse', 'POLines','CasesPerPOLine', 'CasesReceivedSTL','CasesReceivedKC')
head(for_merge, 20)


constraint_slope_stl = (-STL_MAX_CASESIN / STL_MAX_POLINES)
constraint_slope_kc = (-KC_MAX_CASESIN / KC_MAX_POLINES)
x = c(1:max(STL_MAX_POLINES, KC_MAX_POLINES))

stl_function = 18072 + constraint_slope_stl*x
stl_function = ifelse(stl_function < 0, NA, stl_function)

kc_function = 12997 + constraint_slope_kc*x
kc_function = ifelse(kc_function < 0, NA, kc_function)


# Make into dataframe
con_df = data.frame(cbind(x, stl_function, kc_function))
names(con_df) = c('POLines', 'STLConstraint', 'KCConstraint')
con_df$CasesPerPOLineSTL = (con_df$STLConstraint / con_df$POLines)
con_df$CasesPerPOLineKC = (con_df$KCConstraint / con_df$POLines)


# Merge in contextual data
con_df = unique(merge(con_df, for_merge, by='POLines', all.y=TRUE))
head(con_df, 20)

stl = con_df %>% filter(Warehouse == 'Saint Louis')

g = ggplot(data=stl, aes(x=POLines, y=STLConstraint, label=CasesPerPOLine))
constraints_plot_stl = g +  
  geom_point(aes(x=POLines, y=CasesReceivedSTL, size=CasesPerPOLine), colour='blue', alpha=0.7) +
  labs(title='STL Receiving Capacity Constraints in Context of History', x='PO Lines/Day',
       y='Cases Received/Day') +
  geom_hline(yintercept=STL_MAX_CASESIN, colour='black', size=2, alpha=0.15) +
  geom_vline(xintercept=STL_MAX_POLINES, colour='black', size=2, alpha=0.15) +
  geom_line(aes(label=CasesPerPOLineSTL), colour='black', size=2, alpha=0.15) +
  scale_y_continuous(label=comma) +
  geom_smooth(aes(x=POLines, y=CasesReceivedSTL), se=F, colour='black') +
  theme(legend.position='none')



kc = con_df %>% filter(Warehouse == 'Kansas City')

g = ggplot(data=kc, aes(x=POLines, y=KCConstraint, label=CasesPerPOLine))
constraints_plot_kc = g +  
  geom_point(aes(x=POLines, y=CasesReceivedKC, size=CasesPerPOLine), colour='red', alpha=0.7) +
  labs(title='KC Receiving Capacity Constraints in Context of History', x='PO Lines/Day',
       y='Cases Received/Day') +
  geom_hline(yintercept=KC_MAX_CASESIN, colour='black', size=2, alpha=0.15) +
  geom_vline(xintercept=KC_MAX_POLINES, colour='black', size=2, alpha=0.15) +
  geom_line(aes(label=CasesPerPOLineKC), colour='black', size=2, alpha=0.15) +
  scale_y_continuous(label=comma) +
  geom_smooth(aes(x=POLines, y=CasesReceivedKC), se=F, colour='black') +
  theme(legend.position='none')


#library(gridExtra)
#plts = grid.arrange(constraints_plot_stl, constraints_plot_kc, nrow=1)


## for reference to above


#SCATTERPLOT - PO LINES AND CASES RECEIVED
p = ggplot(data=DAILY_SUMMARY, aes(x=PO_._Line_Number, y=Cases_Received, group=Warehouse, label=Date_Received))
SCATTER_POLINES_CASES = p + 
  geom_point(aes(colour=Weekday), alpha=0.4) +
  facet_wrap(~Warehouse, scales='free_x') +
  theme(legend.position='bottom', axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_y_continuous(labels=comma) +
  labs(title='PO Lines/day vs. Cases Received/day', x='PO Lines Received/Day', y='Cases Received/Day') +
  geom_smooth(method='lm', se=F, colour='black', size=.9, alpha=0.3) 

SCATTER_POLINES_CASES
ggplotly(SCATTER_POLINES_CASES)








## Decision tree
library(party)
tree_data = DAILY_SUMMARY
names(tree_data) = c('X','Warehouse','Date','Year','Month','Weekday',
                     'Cases_Received','Weight','Ext_Cost','PO_Lines_Received',
                     'Case_per_PO_Line','Is_Weekend','Is_Monday','Operational_Threshold_Exceeded')

# Create the tree.
output.tree <- ctree(
  Operational_Threshold_Exceeded ~ Cases_Received + PO_Lines_Received + Warehouse, 
  data = tree_data)




```


# <b>Executive Summmary</b> <br><small>This analysis reviews DAILY INBOUND SHIPMENT data from 2015-2016 with the goal of finding criteria for <i>planning & scheduling deliveries</i> amidst operational constraints.<br><br>Operational constraints have been simplified.<br><br>Capacity violations, defined by warehouse, are defined by days in which we exceed:<br>(1) the 95th-percentile of cases received, OR <br>(2) the 95th-percentile of PO lines received.</small> {data-background=#e6e6e6}

## <b>Executive Summary</b> <br><small>This model is simple -- yet can be extended.<br><br>More real-world constraints can be added to the model in future to develop better decision support parameters.<br><br>The most logical next constraint to add in would be receiving labor hours -- defining another operational capacity violation as "days we exceeded X% overtime hours for the receiving crew."<br><br>Further extensions to the model are possible.</small> {data-background=#e6e6e6}





# <b>Defining Capacity</b> <br><small>The following information is based on DAILY DATA.<br><br>This daily information is visualized by house and grouped by either Month or Weekday.<br><br>The visualizations are shown as <a href=https://www.r-bloggers.com/whisker-of-boxplot/>boxplots</a> in order to characterize the distribution of the observations.<br><br>The bottom of the box represents the 25th percentile and the top is the 75th percentile (together, the middle 50%). Outliers (shown by dots) fall outside of 3 standard deviations for that group.</small> {data-background=#e6e6e6}


## Simple Capacity Constraints
```{r cap_cons, echo=FALSE, cache=FALSE, align='center', warning=FALSE, results=FALSE, message=FALSE, fig.width=10, fig.height=6}
datatable(thresh_df, filter='none', selection='none', options=list(dom='t'))
```
<br>
<b><center>Constraints that are not priced into the model include labor availability, receiving dock space, carrier, time of day, number of trucks, full vs. mixed pallets, LTLs, fork lift availability, detention fees and door availability.</b></center>
<ul>
  <li>However, PO lines & cases received dominate the problem</li>
  <li>Avoiding these violations can reduce operational stress</li>
  <li>Even if satisfied, unconsidered constraints may be violated</li>
  <li>Model must be expanded to better represent reality</li>
</ul>


## Capacity Constraint Violations
<b><center>If any of the afforementioned values was exceeded on a certain day, that day was marked as being in "violation" of our capacity to receive.<br><br>Capacity for KC and capacity for STL are shown on the following plots by a red and blue horizontal line, respectively.<br><br>These visuals are meant to display the constraints for contextual purposes.</b></center>


## Cases Received by Weekday
```{r weekday_casess, echo=FALSE, cache=FALSE, align='center', warning=FALSE, results=FALSE, message=FALSE, fig.width=10, fig.height=6}
ggplotly(WEEKDAY_CASES_PLOT)
```

## PO Lines Received by Weekday
```{r weekday_lines, echo=FALSE, cache=FALSE, align='center', warning=FALSE, results=FALSE, message=FALSE, fig.width=10, fig.height=6}
ggplotly(WEEKDAY_POLINES_PLOT)
```

## Cases Received by Month
```{r month_casess, echo=FALSE, cache=FALSE, align='center', warning=FALSE, results=FALSE, message=FALSE, fig.width=10, fig.height=6}
ggplotly(DAILY_CASES_PLOT)
```

## PO Lines Received by Month
```{r month_lines, echo=FALSE, cache=FALSE, align='center', warning=FALSE, results=FALSE, message=FALSE, fig.width=10, fig.height=6}
ggplotly(DAILY_POLINES_PLOT)
```





# <b>Avoiding Capacity Violations</b> <br><small>Again -- this model is simple.<br><br>There are clear upper limits to each house's capacity to receive inventory, and the dominant constraints are the number of PO Lines and the number of Cases received per day.<br><br>The following decision tree model uses a <a href=https://cran.r-project.org/web/packages/partykit/vignettes/ctree.pdf>conditional inference tree algorithm</a> to derive a solution based on the model provided.<br><br>The following is meant to help schedulers.</small> {data-background=#e6e6e6}


## Theoretical Capacity vs History
```{r stl_cap_scatter, echo=FALSE, cache=FALSE, align='center', warning=FALSE, results=FALSE, message=FALSE, fig.width=10, fig.height=6}
ggplotly(constraints_plot_stl)
```

## Theoretical Capacity vs History
```{r kc_cap_scatter, echo=FALSE, cache=FALSE, align='center', warning=FALSE, results=FALSE, message=FALSE, fig.width=10, fig.height=6}
ggplotly(constraints_plot_kc)
```



## Decision Tree - Quick & Dirty
<b><center>Simply abide by this capacity grid.</b></center>
<br><br>
```{r cap_cons2, echo=FALSE, cache=FALSE, align='center', warning=FALSE, results=FALSE, message=FALSE, fig.width=10, fig.height=10}
datatable(thresh_df, filter='none', selection='none', options=list(dom='t'))
```


## Decision Tree - Expanded
```{r decision_tree, echo=FALSE, cache=FALSE, align='center', warning=FALSE, results=FALSE, message=FALSE, fig.width=10, fig.height=6}
# Plot the tree.
plot(output.tree, type='simple')
```


## Decision Tree - In English
<b><center>Do not schedule any more trucks for a given day if:</b></center>
<ul>
  <li>If PO lines is over 379 (both houses)</li>
  <li>Above is false, but cases coming in is over 18,048 (both)</li>
  <li>All above are false, but PO lines exceed 323 (KC)</li>
  <li>All above are false but cases in is over 13,052</li>
</ul>
<br><br>
<b><center>Above takes the sequential approach that can be simplified further.</b></center>


## Decision Tree - In English
<b><center>Subjective Criteria:</b></center>
<ul>
  <li>Try to stagger high PO lines w/ low PO lines</li>
  <li>Subjectively account for kegs -- not tracked</li>
  <li>Consider detention costs at trans-shipment brokers</li>
  <li>Pre-emptively plan put-away -- night crew can help</li>
  <li>Consecutive capacity violations will cause an issue</li>
  <li>If heavy receiving week decide whether to open Sat/Sun</li>
</ul>



# <b>Further Considerations</b> <br><small>The following is based on either limited data or interviews with managers/workers at each location, and should be discounted due to this fact.<br><br> The following information can be quantified in future improvements on this model.<br><br>These factors are certainly relevant to the overall process.</small> {data-background=#e6e6e6}

<!-- # <b>Further Considerations</b><br><small>The following is based on either limited data or interviews with managers/workers at each location, and should be discounted due to this fact.<br><br> The following information can be quantified in future improvements on this model.<br><br>These factors are certainly relevant to the overall process.</small></center> {data-background=#e6e6e6} -->

## Saint Louis Specific
<ul>
  <li>Max trucks to STL's main receiving: 12/day</li>
  <li>Max trucks to STL's beer receiving: 8/day</li>
  <li>Max trucks to STL's LTL/Door1 receiving: 4/day</li>
  <li>STL day receiving crew ~10 people</li>
  <li>Max 2 people in STL cooler limits beer putaway rate</li>
  <li>Receiving space is limited at each door</li>
  <li>Timely clearing of receiving aids efficiency</li>
  <li>Timely bulk to forward pick replenishment aids efficiency</li>
  <li>Kegs are not properly documented in the process</li>
  <li>STL does not put everything away each day</li>
  <li>Receives ~2 transfers from KC per week on avg.</li>
</ul>


## Kansas City Specific
<ul>
  <li>Max trucks to KC's receiving: 12/day</li>
  <li>Avg trucks to KC's receiving : 9/day</li>
  <li>KC day receiving crew 5-6 people on MF & 6-7 on TWR</li>
  <li>3 pallet jacks & 3 Toyota sit down lifts (4th requested)</li>
  <li>Receiving space is typically not a constraint</li>
  <li>Receives ~3 transfers from STL per week</li>
  <li>KC unloads 1 truck at a time</li>
  <li>Kegs are not properly documented in the process</li>
  <li>KC puts everything away on most days</li>
</ul>





# <b>Barriers to Optimality</b> <br><small>Using the afforementioned guidelines in scheduling can reap a marginal benefit.<br><br>However there are barriers.<br><br>The main barriers include the tool used for scheduling shipments, the availability of information for use in scheduling, and an established replenishment policy.<br><br>The first two are necessary to address. The latter should be addressed to speed up the whole process.</small> {data-background=#e6e6e6}



## Data Availability
<b><center>We lack insight into key parameters.</b></center>
<ul>
  <li>Kegs are not specified in DISC receiving data</li>
  <li>Time slots are tracked outside DISC in Excel</li>
  <li>Truck type & receiving door are not specified</li>
  <li>Daily receiving hours is not tracked</li>
  <li>No data on our network of carriers & their costs</li>
  <li>No data on average lead time per carrier/supplier</li>
</ul>


## Scheduling Tool/Process
<b><center>The current tool is an Excel document.</b></center>
<ul>
  <li>Data is inconsistent and difficult to extract</li>
  <li>Prone to error when others open the document</li>
  <li>Difficult to analyze from the document</li>
  <li>Cancellations by brokers cause disruptions</li>
  <li>Inventory aggregators ship unpredictably</li>
  <li>Multiple brokers scheduled for one trans-shipment</li>
  <li>Ops team currently working miracles with available tool</li>
</ul>



## Forward Pick Replenishment
<b><center>A few tweaks may benefit receiving's efficiency. These are subjective recommendations based on observations & interviews.</b></center>
<ul>
  <li>Prompt night putaways following busy receiving days</li>
  <li>Proactive replenishment will increase efficiency</li>
  <li>Potential ERP triggers for replenishment tied to sales</li>
</ul>






# <b>Conclusions</b> <br><small>This model can and should be refined over time.<br><br>By staying within these constraints we can cut out most disruptive receiving days.<br><br>By addressing putaways and scheduling the entire process can be made more efficient.<br><br>Diligent planning of this function in the new ERP will reap significant benefits.</small> {data-background=#e6e6e6}






# <b>Questions, Comments & Discussion</b> <br><small>Please take this time to clarify understanding, raise concerns, or provide input on the findings.<br><br>Thank you for your time!</small> {data-background=#e6e6e6}










# <b>Parting Words of Wisdom</b> <br><small>"Restlessness is discontent and discontent is the first necessity of progress. Show me a thoroughly satisifed man and I will show you a failure." -Thomas Edison<br><br>"No one would have crossed the ocean if he could have gotten off the ship in the storm." -Charles Kettering</small> {data-background=#e6e6e6}





















