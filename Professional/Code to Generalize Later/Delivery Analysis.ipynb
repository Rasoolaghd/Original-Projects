{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n",
    "\n",
    "Data utilized comes from the Daily Report.\n",
    "\n",
    "# Goals\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import glob\n",
    "import re\n",
    "import string\n",
    "\n",
    "pd.set_option('max_rows', 99999999)\n",
    "pd.set_option('max_columns', 99999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_date_stl(file, year):\n",
    "    '''Takes date from file name'''\n",
    "    regex_criteria = re.compile(r'[0-9]+-[0-9]+')    \n",
    "    dat = re.findall(regex_criteria, file)\n",
    "    exclude = set(string.punctuation)\n",
    "    dat = ''.join(d for d in dat if d not in exclude)\n",
    "    dat = str(dat + '-' + year)\n",
    "    dat = dt.strptime(str(dat), \"%m-%d-%Y\").date()\n",
    "    return dat\n",
    "\n",
    "def extract_stl_production_tab(file, year):\n",
    "    '''\n",
    "    Takes in and formats Production Tab from Daily Report. \n",
    "    Extracts date from filename and creates index.\n",
    "    Puts into a dictionary of dataframes \n",
    "    for input into a pandas DataFrame.\n",
    "    '''\n",
    "    dtypes = {'Date':dt.date, 'Warehouse':str,'LOC':str,'RTE':str,'Driver':str,'Truck#':str,\n",
    "            'Stops':np.float64,'TTL Cs/splt':np.float64,'Cs':np.float64,'Btls':np.float64,\n",
    "            'Start Hr':str, 'End Hr':str,'Ttl Hrs':str,'Ttl Mi':np.float64 }\n",
    "    try:\n",
    "        df = pd.read_excel(file, sheet_name='Production', converters=dtypes)\n",
    "    except ValueError:\n",
    "        df = pd.read_excel(file, sheet_name='Production')        \n",
    "        \n",
    "    dat = extract_date_stl(file, year)\n",
    "    \n",
    "    df['Date'] = dat \n",
    "    df['Month'] = dat.strftime('%B')\n",
    "    df['Weekday'] = dat.strftime('%A')\n",
    "    df['WeekNumber'] = dat.strftime('%U')\n",
    "    df['DOTM'] = dat.strftime('%d')\n",
    "    df['Warehouse'] = 'STL'\n",
    "    \n",
    "    keep_cols = ['Date','Warehouse','LOC','RTE','Driver','Truck#','Stops',\n",
    "                 'TTL Cs/splt','Cs','Btls','Start Hr',\n",
    "                 'End Hr','Ttl Hrs','Ttl Mi','Month','Weekday','WeekNumber',\n",
    "                 'DOTM']\n",
    "    df = df[keep_cols].drop_duplicates()\n",
    "    \n",
    "    WAREHOUSE, ROUTE = df.Warehouse.astype(str), df.RTE.astype(str)\n",
    "    new_index = WAREHOUSE + '_' + ROUTE \n",
    "    \n",
    "    df.set_index(new_index, inplace=True)\n",
    "    \n",
    "    df = df[df['Driver'] != 'Totals:']        \n",
    "    df = df.sort_values(['Stops','TTL Cs/splt'], ascending=False).reset_index(drop=False)\n",
    "    \n",
    "    df['Date'] = df['Date'].replace(to_replace='NaN', value='')\n",
    "    df = df[df['Date'].isnull() == False]\n",
    "    \n",
    "    drop_dumb_shit = lambda col: str(col).lower().replace(' ', '_').replace('#', '').replace('.', '')\n",
    "    df.columns = [drop_dumb_shit(col) for col in df.columns]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Update years like on velocity\n",
    "files_2018 = 'N:\\\\Daily Report\\\\2018\\\\*\\\\*.xls*'\n",
    "files_2017 = 'N:\\\\Daily Report\\\\2017\\\\*\\\\*.xls*'\n",
    "files_2016 = 'N:\\\\Daily Report\\\\2016\\\\*\\\\*.xls*'\n",
    "\n",
    "file_list = {'2016': files_2016, '2017': files_2017, '2018': files_2018}\n",
    "\n",
    "stl_production = pd.DataFrame()        \n",
    "for k, v in file_list.items():\n",
    "    flist = glob.glob(v)\n",
    "    yr = k\n",
    "    for file in flist:\n",
    "        if 'copy' in str(file).lower():\n",
    "            print('Excluding file:  {}'.format(file))\n",
    "            pass\n",
    "        elif '~$' in str(file):\n",
    "            print('Excluding file:  {}'.format(file))\n",
    "            pass\n",
    "        else:\n",
    "            df  = extract_stl_production_tab(file, year=yr)\n",
    "            stl_production = stl_production.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stl_production.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix_cols = ['date', 'warehouse', 'rte']\n",
    "stl_production.sort_values(ix_cols, inplace=True)\n",
    "stl_production.set_index(ix_cols, inplace=True, drop=False)\n",
    "stl_production.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(stl_production.loc[stl_production['loc']=='COL', 'index'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stl_production['delivery_day'] = stl_production['date'] + pd.to_timedelta(1, unit='d')\n",
    "stl_production['delivery_weekday'] = stl_production['delivery_day'].apply(lambda d: d.weekday())\n",
    "wday_map = dict(zip(np.arange(0, 7), ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']))\n",
    "stl_production['delivery_weekday'] = stl_production['delivery_weekday'].map(wday_map)\n",
    "stl_production.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nontrue_routes = ['STL_70', 'STL_91', 'STL_PR', 'STL_nan', 'STL_90', 'STL_93', 'STL_13', 'STL_3', 'STL_25']#['STL_nan', 'STL_PR', 'STL_90']#['STL_70', 'STL_91', 'STL_PR', 'STL_nan', 'STL_90', 'STL_93', 'STL_13', 'STL_3', 'STL_25']\n",
    "stl_production['non_true_rtes'] = stl_production['index'].isin(nontrue_routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "check_cols = ['loc', 'rte', 'driver', 'truck', 'stops', 'ttl_cs/splt']\n",
    "x_check = stl_production.loc[stl_production.non_true_rtes == True, check_cols].reset_index(drop=True)\n",
    "fname = 'N:/Operations Intelligence/Operations Research/Delivery Analysis Post Schlafly/for_bob_to_check.xlsx'\n",
    "x_check = x_check.drop_duplicates()\n",
    "# x_check.to_excel(fname)\n",
    "x_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def stl_daily_route_summary(stl_production):\n",
    "    grpby_df = stl_production.loc[stl_production['loc'].isin(['STL', 'COL'])]\n",
    "    grpby_df = grpby_df.loc[grpby_df.non_true_rtes == False]\n",
    "    grp_cols = ['warehouse', 'loc', 'date']\n",
    "    agg_funcs = {'rte': pd.Series.nunique, 'stops': np.sum, 'ttl_cs/splt': np.sum}\n",
    "    grpby_df = pd.DataFrame(grpby_df.groupby(grp_cols).agg(agg_funcs)).reset_index(drop=False)\n",
    "    return grpby_df\n",
    "\n",
    "stl_daily = stl_daily_route_summary(stl_production)\n",
    "stl_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge in calendar data\n",
    "def generate_calendar(year, drop_index=False):\n",
    "    '''\n",
    "    Simple function to generate a calendar containing\n",
    "    US holidays, weekdays and  holiday weeks.\n",
    "    '''\n",
    "    from pandas.tseries.offsets import YearEnd\n",
    "    from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "    \n",
    "    start_date = pd.to_datetime('1/1/'+str(year))\n",
    "    end_date = start_date + YearEnd()\n",
    "    DAT = pd.date_range(str(start_date), str(end_date), freq='D')\n",
    "    MO = [d.strftime('%B') for d in DAT]\n",
    "    holidays = USFederalHolidayCalendar().holidays(start=start_date, end=end_date)\n",
    "\n",
    "    cal_df = pd.DataFrame({'date':DAT, 'month':MO})\n",
    "    cal_df['year'] = [format(d, '%Y') for d in DAT]\n",
    "    cal_df['weekday'] = [format(d, '%A') for d in DAT]\n",
    "    cal_df['is_weekday'] = cal_df.weekday.isin(['Monday','Tuesday','Wednesday','Thursday','Friday'])\n",
    "    cal_df['is_weekday'] = cal_df['is_weekday'].astype(int)\n",
    "    cal_df['is_holiday'] = cal_df['date'].isin(holidays)\n",
    "    cal_df['is_holiday'] = cal_df['is_holiday'].astype(int)\n",
    "    cal_df['is_holiday_week'] = cal_df.is_holiday.rolling(window=7,center=True,min_periods=1).sum()\n",
    "    cal_df['is_holiday_week'] = cal_df['is_holiday_week'].astype(int)\n",
    "    \n",
    "    if not drop_index: cal_df.set_index('date', inplace=True)\n",
    "    \n",
    "    return cal_df\n",
    "\n",
    "def make_calendars(year_list, drop_index):\n",
    "    cal_df = pd.DataFrame()\n",
    "    for year in year_list:\n",
    "        cal_df = cal_df.append(generate_calendar(year, drop_index=drop_index))\n",
    "    return cal_df\n",
    "\n",
    "year_list = ['2016', '2017', '2018']\n",
    "cal_df = make_calendars(year_list, drop_index=True)\n",
    "cal_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, axes = plt.subplots(1, 2, figsize=(17, 6))\n",
    "for i, loc in enumerate(['STL', 'COL']):\n",
    "    _df = stl_daily.loc[stl_daily['loc'] == loc]\n",
    "    ax = axes[i]\n",
    "    ax.plot(_df['date'], _df['rte'])\n",
    "    ax.set_title('Routes per Day for {}'.format(loc))\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylabel('Number of Market Routes')\n",
    "    ax.grid(alpha=.4)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(90)\n",
    "plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(17, 6))\n",
    "for i, loc in enumerate(['STL', 'COL']):\n",
    "    _df = stl_daily.loc[stl_daily['loc'] == loc]\n",
    "    ax = axes[i]\n",
    "    ax.hist(_df['rte'], bins=_df['rte'].max()-_df['rte'].min())\n",
    "    ax.axvline(_df['rte'].mean(), linestyle='--', color='r')\n",
    "    ax.axvline(_df['rte'].mean()-_df['rte'].std(), linestyle='-.', color='y')\n",
    "    ax.axvline(_df['rte'].mean()+_df['rte'].std(), linestyle='-.', color='y')\n",
    "    ax.set_title('Histogram of Routes per Day for {}'.format(loc))\n",
    "    ax.set_xlabel('Count of Routes per Day')\n",
    "    ax.set_ylabel('Number of Observations')\n",
    "    ax.grid(alpha=.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stl_production.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delivery Equipment Leasing 2016-2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.ExcelFile.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = 'N:\\\\Operations Intelligence\\\\Operations Research\\\\Delivery Analysis Post Schlafly\\\\'\n",
    "equip_leasing_xlsx = pd.ExcelFile(base_dir + 'Delivery Equipment Leasing  2016-2018.xlsx')\n",
    "rentals = equip_leasing_xlsx.parse('All Data', skiprows=4)\n",
    "rentals.Location = rentals.Location.map({1: 'Kansas City', 2: 'Saint Louis', 3: 'Columbia', 4: 'Springfield'})\n",
    "rentals.Date = rentals.Date.apply(pd.to_datetime)\n",
    "rentals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rentals.Journal.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rentals.groupby(['Location', 'Date']).agg({'Amount': np.sum, 'Reference': pd.Series.nunique})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rentals_byday = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
